{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c94169bf",
   "metadata": {},
   "source": [
    "<p> <center> <a href=\"../../Start_Here.ipynb\">Home Page</a> </center> </p>\n",
    "\n",
    " \n",
    "<div>\n",
    "    <span style=\"float: left; width: 33%; text-align: left;\"><a href=\"Multitask_Prompt_and_PTuning.ipynb\">Previous Notebook</a></span>\n",
    "    <span style=\"float: left; width: 33%; text-align: center;\">\n",
    "       \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e59f23f",
   "metadata": {},
   "source": [
    "# Lab Activity 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0469a34d",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "\n",
    "In this lab, you are to reproduce the p-tuning and prompt-tuning process for the question-answering task using the CUAD dataset already available. To complete the activity, you are to implement the following steps:\n",
    "\n",
    "- Understand the structure of the CUAD dataset and process the `CUAD_v1.json` file into a training and validation set. You are free to decide the split ratio. More detail is given below.\n",
    "- Setup your P-Tuning Model Config using omegaconf\n",
    "- Create the prompt formatting template and set the task\n",
    "- Set the pre-trained GPT model as `nemo_gpt1.3B_fp16.nemo` \n",
    "- Build the PyTorch lightning trainer and set all hyperparameters\n",
    "- Create the NeMo experiment manager\n",
    "- Run your p-tuning session\n",
    "- Restore your p-tuned model to run inference\n",
    "\n",
    "\n",
    "Part of the code is written for you. You are to complete the rest by filling in the statements with the missing value(s) in the commented areas of the notebook. We recommend consciously setting/modifying the `config.trainer.max_epochs` value as it determines the time to complete the lab. The lab activity should not exceed `45 mins`; therefore, the value of `config.trainer.max_epochs` should be between `1 and 6` as one epoch may take up to `7 mins`. If you plan to exceed these values, run this notebook after the Bootcamp active hours.\n",
    "\n",
    "Note: *You are not expected to get the best result as this activity is for learning. To achieve better results, you can modify parameters: the number of epochs, learning rate, batch size, max step, training, and validation set sample size*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e5a607",
   "metadata": {},
   "source": [
    "<div style=\"text-align:left; color:#FF0000; height:40px; text-color:red; font-size:20px\">Before you run this notebook, please close and shut down the kernel of the previous notebooks. </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b378e8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import wget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5e82f0",
   "metadata": {},
   "source": [
    "# Tasks and Datasets\n",
    "We will be using p-tuning to teach our GPT model to do **Question Answering**.\n",
    "\n",
    "We will be using the [Contract Understanding Atticus Dataset (CUAD) v1](https://www.atticusprojectai.org/cuad). It is a corpus of more than 13,000 labels in 510 commercial legal contracts that have been manually labeled to identify 41 categories of essential clauses that lawyers look for when reviewing contracts in connection with corporate transactions. \n",
    "\n",
    "CUAD is curated and maintained by The Atticus Project, Inc. to support NLP research and development in legal contract review. Analysis of CUAD can be found at https://arxiv.org/abs/2103.06268. Code for replicating the results and the trained model can be found at https://github.com/TheAtticusProject/cuad.\n",
    "\n",
    "To download the CUAD dataset, you can visit the [CUAD v1 website](https://www.atticusprojectai.org/cuad).\n",
    "\n",
    "\n",
    "\n",
    "## CUAD Dataset Structure\n",
    "### Data Instances\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38512f68",
   "metadata": {},
   "source": [
    "```json\n",
    "...\n",
    "{  \n",
    "    \"answers\": {\n",
    "        \"answer_start\": [44],\n",
    "        \"text\": [\"DISTRIBUTOR AGREEMENT\"]\n",
    "    },\n",
    "    \"context\": \"EXHIBIT 10.6\\n\\n DISTRIBUTOR AGREEMENT\\n\\n THIS  DISTRIBUTOR  AGREEMENT (the  \\\"Agreement\\\")  is made    by and between Electric City Corp.,  a Delaware  corporation  (\\\"Company\\\")  and Electric City of Illinois LLC (\\\"Distributor\\\") this 7th day of September, 1999...\",\n",
    "    \"id\": \"LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGREEMENT__Document Name_0\",\n",
    "    \"question\": \"Highlight the parts (if any) of this contract related to \\\"Document Name\\\" that should be reviewed by a lawyer. Details: The name of the contract\",\n",
    "    \"title\": \"LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGREEMENT\"\n",
    "}\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac45ebd",
   "metadata": {},
   "source": [
    "### Data Fields\n",
    "\n",
    "- **id:** a string feature representing a unique question ID.\n",
    "- **title:** represents domain/topic of discussion or document title.\n",
    "- **context**: represents a group sentences or document where the answer(s) to a question(s) lies. It is possible for a single context to have two or more questions.\n",
    "- **question:** a text that requires an answer from a context.\n",
    "- **answers:** a text list containing a dictionary of responses and the index `(answer_start)` where the answer text starts within a context."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3a350b",
   "metadata": {},
   "source": [
    "More information on CUAD dataset can be found on the [CUAD v1 website](https://www.atticusprojectai.org/cuad) or at the [Hugging Face Datasets page](https://huggingface.co/datasets/cuad).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f6ab82",
   "metadata": {},
   "source": [
    "## File Formats\n",
    "\n",
    "The files in CUAD v1 include 1 CSV file, 1 SQuAD-style JSON file, 28 Excel files, 510 PDF files, and 510 TXT files.\n",
    "\n",
    "-  1 master clauses CSV: an 83-column 511-row file. The first column contains the contracts' names corresponding to the PDF and TXT files in the \"full_contracts_pdf\" and \"full_contracts_txt\" folders. The remaining columns have (1) text context (sometimes referred to as clause) and (2) human-input answers that correspond to each of the 41 categories in these contracts. \n",
    "\n",
    "- 1 SQuAD-style JSON: this file is derived from the master clauses CSV to follow the same format as SQuAD 2.0 (https://rajpurkar.github.io/SQuAD-explorer/explore/v2.0/dev/), a question answering dataset whose answers are similarly spans of the input text. The exact structure of the JSON format exactly mimics that of SQuAD 2.0 for compatibility with prior work. We also provide Python scripts for processing this data for ease of use.\n",
    "\n",
    "- 28 Excels: a collection of Excel files containing clauses responsive to each category. The first column contains the contracts' names corresponding to the PDF and TXT files in the \"full_contracts_pdf\" and \"full_contracts_txt\" folders. The remaining columns have (1) text context (clause) corresponding to one or more Categories that belong in the same group as identified in the \"Category List\" below, and (2), in some cases, human-input answers that correspond to such text context. Each file is named \"Label Report - [label/group name] (Group [number]).xlsx\"\n",
    "\n",
    "- 510 entire contract PDFs: a collection of the underlying contracts we used to extract the labels. Each file is named \"[document name].pdf\". These contracts are in a PDF format and are not labeled. The entire agreement PDFs contain raw data and are provided for context and reference.\n",
    "\n",
    "- 510 full contract TXTs: a collection of TXT files of the underlying contracts. Each file is named \"[document name].txt\". These contracts are in a plaintext format and are not labeled. The full contract TXTs contain raw data and are provided for context and reference.\n",
    "\n",
    "We will use the SQuAD-style JSON format dataset (CUAD_v1.json) to facilitate work with prior work and existing language models. In this dataset, each contract is broken up into paragraphs. For each provision category, a model must predict the span of text (if any) in that paragraph corresponding to that category."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6160a26d",
   "metadata": {},
   "source": [
    "**Extract from SQuAD-style JSON format of CUAD dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec4e0fd6",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "  \"qas\": [\n",
    "    {\n",
    "      \"answers\": [{ \"text\": \"Promotion and Distribution Agreement\",\"answer_start\": 307 }],\n",
    "      \"id\": \"WHITESMOKE,INC_11_08_2011-EX-10.26-PROMOTION AND DISTRIBUTION AGREEMENT__Document Name\",\n",
    "      \"question\": \"Highlight the parts (if any) of this contract related to \\\"Document Name\\\" that should be reviewed by a lawyer. Details: The name of the contract\",\n",
    "      \"is_impossible\": false\n",
    "    },\n",
    "    {\n",
    "      \"answers\": [{\"text\": \"Distributor\",\"answer_start\": 625 },\n",
    "                  {\"text\": \"Google\",\"answer_start\": 644 },\n",
    "                  {\"text\": \"Google Inc\",\"answer_start\": 644 },\n",
    "                  {\"text\": \"Whitesmoke Inc.\",\"answer_start\": 492 }],\n",
    "      \"id\": \"WHITESMOKE,INC_11_08_2011-EX-10.26-PROMOTION AND DISTRIBUTION AGREEMENT__Parties\",\n",
    "      \"question\": \"Highlight the parts (if any) of this contract related to \\\"Parties\\\" that should be reviewed by a lawyer. Details: The two or more parties who signed the contract\",\n",
    "      \"is_impossible\": false\n",
    "    },\n",
    "    ...............\n",
    "    {\n",
    "      \"answers\": [],\n",
    "      \"id\": \"WHITESMOKE,INC_11_08_2011-EX-10.26-PROMOTION AND DISTRIBUTION AGREEMENT__Agreement Date\",\n",
    "      \"question\": \"Highlight the parts (if any) of this contract related to \\\"Agreement Date\\\" that should be reviewed by a lawyer. Details: The date of the contract\",\n",
    "      \"is_impossible\": true\n",
    "    }\n",
    "  ],\n",
    "  \"context\": \"Exhibit 10.26    CONFIDENTIAL TREATMENT HAS BEEN REQUESTED AS TO CERTAIN PORTIONS OF THIS DOCUMENT.      EACH SUCH PORTION,  WHICH HAS BEEN OMITTED HEREIN AND REPLACED WITH AN ASTERISK [*], HAS BEEN FILED SEPARATELY      WITH THE SECURITIES AND EXCHANGE COMMISSION.     PROMOTION AND DISTRIBUTION AGREEMENT     This Promotion and        Distribution Agreement including all exhibits (collectively referred to as the \\\"Agreement\\\"), effective as of 1    August 2011 (the  \\\"Effective Date\\\"), is made by and between Whitesmoke Inc., with registered offices/principle    place of business at 501 Silverside Road, Suite 105,  Wilmington DE 19809, USA, (\\\"Distributor\\\"),......\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ec6a466",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### 1. Dataset splitting: Training and Testing Samples\n",
    "\n",
    "- A CuAD dataset in the SQuAD-like JSON format is provided as a single dataset file.\n",
    "- You must split the dataset into separate training and testing subsets to facilitate model training and evaluation.\n",
    "- You can achieve this using the following code snippet, demonstrating the dataset-splitting process.\n",
    "\n",
    "Run the cell below to download the CUAD dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "424764da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1C5T6Na63oATxn8rBmZ5YT55mjrs7WTEG&confirm=t\n",
      "To: /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/data/CUAD_v1.json\n",
      "100%|██████████████████████████████████████| 40.1M/40.1M [00:00<00:00, 63.2MB/s]\n"
     ]
    }
   ],
   "source": [
    "!python3 ../../source_code/dataset_cuad.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e1c6bc",
   "metadata": {},
   "source": [
    "- Before running the code snippet for dataset splitting, please ensure that the `CUAD_v1.json` dataset file exists in the `/workspace/data` project directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9225a3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "\n",
    "def split_dataset(data, train_ratio):\n",
    "    # Calculate the number of training samples\n",
    "    num_train = int(len(data) * train_ratio)\n",
    "\n",
    "    # Shuffle the data\n",
    "    random.shuffle(data)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "    train_data = data[:num_train]\n",
    "    test_data = data[num_train:]\n",
    "\n",
    "    return train_data, test_data\n",
    "\n",
    "# Set the working directory\n",
    "data_directory = '../../data/'\n",
    "\n",
    "# Define the path to the downloaded CUAD_v1.json dataset \n",
    "# Make sure that the CUAD_v1.json dataset is in the same directory as the script or provide the correct path to it in the cuad_file_path variable.)\n",
    "cuad_file_path = os.path.join(data_directory, 'CUAD_v1.json')\n",
    "\n",
    "# Load the JSON file\n",
    "with open(cuad_file_path) as f:\n",
    "    json_data = json.load(f)\n",
    "\n",
    "# Extract the data from the JSON file\n",
    "data = json_data['data']\n",
    "\n",
    "################### You may modify to the train ratio of your preference ############################\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "train_data, test_data = split_dataset(data, train_ratio=0.9)\n",
    "\n",
    "#####################################################################################################\n",
    "\n",
    "# Create the 'data' directory if it doesn't exist\n",
    "cuad_directory = os.path.join(data_directory, 'cuad')\n",
    "if not os.path.exists(cuad_directory):\n",
    "    os.makedirs(cuad_directory)\n",
    "\n",
    "# Save the train data into a separate JSON file\n",
    "train_file_path = os.path.join(cuad_directory, 'train_dataset.json')\n",
    "with open(train_file_path, 'w') as train_file:\n",
    "    json.dump({'version': json_data['version'], 'data': train_data}, train_file)\n",
    "\n",
    "# Save the test data into a separate JSON file\n",
    "test_file_path = os.path.join(cuad_directory, 'test_dataset.json')\n",
    "with open(test_file_path, 'w') as test_file:\n",
    "    json.dump({'version': json_data['version'], 'data': test_data}, test_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25fed2c2",
   "metadata": {},
   "source": [
    "### 2. Preprocessing the train and test datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f1fd466",
   "metadata": {},
   "source": [
    "The prompt learning dataset loader accepts a list of JSON/dictionary objects or a list of JSON file names where each file contains a collection of JSON objects. Each JSON object must include the field `taskname,` a string identifier for the task the data example corresponds to. They should also have one or more fields corresponding to different sections of the discrete text prompt. The input data might look like:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"taskname\": \"cuad\", \"context\": [CONTEXT_PARAGRAPH_TEXT1], \"question\": [QUESTION_TEXT1], \"answer\": [ANSWER_TEXT1]},\n",
    "    {\"taskname\": \"cuad\", \"context\": [CONTEXT_PARAGRAPH_TEXT2], \"question\": [QUESTION_TEXT2], \"answer\": [ANSWER_TEXT2]},\n",
    "]\n",
    "```\n",
    "\n",
    "These additional fields can be unlimited and will be used to help map different parts of the discrete text input to a prompt template you define."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743388a7",
   "metadata": {},
   "source": [
    "Set the working directory as `WORK_DIR` and the data directory as `CUAD_DIR.` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f65062f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "WORK_DIR = '../../'\n",
    "CUAD_DIR = \"../../data/cuad\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7721e9b",
   "metadata": {},
   "source": [
    "Make a directory to store Python scripts for multitask p-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "750d6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "SCRIPT_DIR = os.path.join(WORK_DIR, \"source_code/activity2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7f60fe",
   "metadata": {},
   "source": [
    "Preprocessing the dataset using the `prompt_learning_cuad_preprocessing.py` script located in the `source_code` directory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe1bc004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving train split to ../../data/cuad/cuad_train.jsonl\n",
      "100%|█████████████████████████████████████| 6071/6071 [00:01<00:00, 4386.72it/s]\n",
      "Saving val split to ../../data/cuad/cuad_val.jsonl\n",
      "100%|███████████████████████████████████████| 631/631 [00:00<00:00, 4244.35it/s]\n",
      "Saving test split to ../../data/cuad/cuad_test_ground_truth.jsonl\n",
      "100%|█████████████████████████████████████| 2091/2091 [00:00<00:00, 5737.65it/s]\n",
      "Saving test split to ../../data/cuad/cuad_test.jsonl\n",
      "100%|█████████████████████████████████████| 2091/2091 [00:00<00:00, 5765.94it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocess cuad data\n",
    "!python $WORK_DIR/source_code/prompt_learning_cuad_preprocessing.py --data-dir {CUAD_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e0de4a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"taskname\": \"cuad\", \"context\": \"Exhibit 10.11\\n\\nDATED 26 September 2019\\n\\nBicycleTX Ltd\\n\\nand\\n\\nNigel Crockett\\n\\n___________________________________________________\\n\\nSERVICE AGREEMENT\\n\\n___________________________________________________\\n\\n\\n\\n\\n\\nTHIS AGREEMENT is made on 26 September 2019\\n\\nBETWEEN:\\n\\n(1) BICYCLETX LIMITED a company incorporated under the laws of England and Wales (Company Number 11036101) whose registered office is at Building 900 Babraham Research Campus, Babraham, Cambridgeshire, CB22 3AT, United Kingdom (the \\\"Company\\\"); and\\n\\n(2) NIGEL CROCKETT of (the ''Employee\\\").\\n\\nIT IS AGREED as follows:\\n\\n1. COMMENCEMENT OF EMPLOYMENT\\n\\n1.1 This Agreement shall take effect 26  September 2019 (the \\\"Effective Date\\\").\\n\\n1.2 Your employment shall commence on 26  September 2019 and shall continue unless and until either party gives notice to the other in accordance with paragraph 11 below. No employment with a previous employer is deemed to be continuous with your employment with the Company.\\n\\n1.3 You warrant that by entering into this Agreement or any other arrangements with the Company you will not be in breach of or subject to any express or implied terms of any contract with, or other obligation to, any third party binding on you, including, without limitation, any notice period or the provisions of any restrictive covenants or confidentiality obligations arising out of any employment with any other employer or former employer.\\n\\n1.4 You warrant that you have the right to work in the United Kingdom and you agree to provide to the Company copies of all relevant documents in this respect at the request of the Company. If at any time during the course of this Agreement you cease to have the right to work in the United Kingdom the Company may immediately terminate your employment without payment of compensation.\\n\\n2. JOB TITLE\\n\\n2.1 You shall serve as Chief Business Officer (\\\"CBO\\\") reporting to the CEO. The nature of the Company's business may result in changes occurring to the content of your role from time to time. You may also be required to carry out such additional or alternative tasks as may from time to time be reasonably required of you consistent with your executive level and job title, provided that these do not fundamentally change or undermine your position.\\n\\n2.2 You shall faithfully and diligently perform such duties as you are required to undertake from time to time and exclusively devote the whole of your working time, skills, ability and attention to the business of the Company and use your best endeavours to promote the interests and reputation of the Company and (where applicable) any Group Company.\\n\\n2.3 The Company may require you to carry out work for, or become a director or officer of, any Group Company at any time.\\n\\n3. PLACE OF WORK\\n\\nThe Company's offices at Building 900, Babraham Research Campus, Babraham, Cambridge,\\n\\n1\\n\\nth\\n\\nth\\n\\n\\n\\n\\n\\nUK or such other location as the Company may reasonably determine. The CBO position may require extensive international travel on business.\\n\\n4. REMUNERATION\\n\\n4.1 Your salary will be USD370,000 per annum paid monthly in arrears on or about the last working day of each month (less statutory and voluntary deductions) (\\\"Salary\\\"). Salary will be converted to GBP and paid in GBP based on the USD/GBP Bank of England daily spot exchange rate applicable on the date of this Agreement, with the exchange rate being revised according to the prevailing Bank of England daily spot exchange rate applicable on 1 January of each year. Your Salary will be reviewed annually in accordance with the Company's practices from time to time (which is expected to be by the end of the first quarter of each year). You will be notified in writing of any changes to your Salary or benefits.\\n\\n4.2 You agree that the Company may deduct from the Salary or any other sum due to you (including any pay in lieu of notice) any amounts due to the Company including, without limitation, any overpayment of salary, loan or advance.\\n\\n4.3 For the purposes of this Agreement your earned salary shall mean the proportion of your Salary earned by and due to you in each calendar year of employment with the Company (\\\"Earned Salary\\\").\\n\\n4.4 Annual Performance Bonuses:\\n\\nYou will be eligible to participate in the Company's discretionary annual performance related bonus scheme to a maximum value of 35% of your Earned Salary in relation to your performance against agreed annual corporate and personal performance objectives as set out below (the \\\"Annual Performance Bonus\\\"). That is, if the compensation committee (the \\\"Compensation Committee\\\") of the board of directors (the \\\"Board\\\") of the Company's parent company, Bicycle Therapeutics plc (\\\"BTL\\\") determines that you have completed all such corporate and personal objectives to its satisfaction in a given year, your bonus would be 35% of your Earned Salary in that year, excluding any other bonuses in this offer. Such bonus may be payable in cash or, in whole or in part, in share options in BTL, as agreed by you and the Compensation Committee following notification by you of your preference at least 90 days prior to the normal payment date (and in the case of share options with the appropriate HMRC valuation process (if required by the Compensation Committee) and Board approval so as to be compliant with BTL's share option plan rules), with due consideration for the operational requirements of the Company at that time in your role as CBO.\\n\\nAny Annual Performance Bonus paid will not be pensionable and are subject to statutory applicable tax and National Insurance deductions. Performance will be assessed by the Compensation Committee at the end of each calendar year, against annual corporate and personal performance objectives agreed between you and the Board at the start of each calendar year, with any such bonus being payable in the first quarter of the following year. Qualification for your Annual Performance Bonus will require that you are employed by the Company (and have not served notice of termination of your employment to the Company) on 31 December of the year to which your bonus entitlement applies.\\n\\n2\\n\\n\\n\\n\\n\\n4.5 Equity Incentives\\n\\nBTL has established the Bicycle Therapeutics 2019 Share Option Plan (the \\\"Option Plan\\\").\\n\\nOn or as soon as practicable following the Effective Date, it is intended that you will be granted an option under the Option Plan to acquire 107,417 ordinary shares in the capital of BTL (\\\"Shares\\\") (representing approximately 0.6% of the Company's issued share capital as at the Effective Date).\\n\\nIn addition, and conditional on completion of a transaction on terms set out below, you will be granted a second option under the Option Plan, such option being one of:\\n\\n(a) an option to acquire 44,757 Shares (representing approximately 0.25% of the Company's issued share capital as at the Effective Date) granted as soon as practicable following the completion of a transaction approved by the Board on terms which include an upfront payment of at least USD30,000,000 and per product downstream milestone payments of at least USD300,000,000; or\\n\\n(b) an option to acquire 22,378 Shares (representing approximately 0.125% of the Company's issued share capital as at the Effective Date) granted as soon as practicable following the completion of a transaction approved by the Board on terms which include an upfront payment of USD24,000,000 and per product downstream milestone payments of USD240,000,000; or\\n\\n(c) an option to acquire such number of Shares (falling between 0.125% and 0.25% of the Company's issued share capital as at the Effective Date as the Board shall determine in its absolute discretion) granted as soon as practicable following completion of a transaction approved by the Board on terms which include an upfront payment greater than USD24,000,000 but less than USD 30,000,000, and per product downstream milestone payments greater than USD240,000,000 but less than USD 300,000,000.\\n\\nAny options granted under this paragraph 4.5 shall be subject to (i) the approval of the Board and/or the Compensation Committee; (ii) the rules of the Option Plan (as amended from time to time); and (iii) the terms of the option grant documentation which will be provided to you following such grant.\\n\\n5 BENEFITS\\n\\n5.1 The Company currently operates a personal pension plan provided by Scottish Widows Group. The Company will pay a sum equivalent to 12 % of your basic annual earned salary into a personal pension plan selected by the Company. You may make additional contributions if you wish, but this is not mandatory. In the event that you elect, of your own volition, to opt-out of the Company's pension scheme then the Company will pay you in equal monthly instalments in arrears (less statutory deductions) a sum equivalent to the contribution that it would have made into your pension scheme (the \\\"Cash Equivalent Payment\\\") less the Employer's National Insurance Contribution cost incurred by the Company as a result of making the Cash Equivalent Payment.\\n\\n5.2 The Company currently operates a private healthcare scheme and subject to acceptance by the insurer on reasonable terms, you will be entitled to join.\\n\\n3\\n\\n\\n\\n\\n\\n5.3 The Company operates a death in service scheme which you automatically join upon commencement of employment.\\n\\n5.4 Further details regarding benefits will be provided upon commencement of your employment. The Company reserves the right to replace or supplement any or all of the scheme(s) referred to in this paragraph 5, or to amend them at any time without compensation, provided that equivalent scheme(s) providing a similar level of benefit are put in place.\\n\\n6 EXPENSES\\n\\nThe Company shall reimburse all reasonable out of pocket expenses properly incurred by you in the performance of the duties under this Agreement including travelling, subsistence and entertainment expenses provided you follow the Company's guidelines/allowances in force at the relevant time and provided that you shall, where reasonably practicable, provide the Company with vouchers, invoices or such other evidence of such expenses as the Company may reasonably require.\\n\\n7 HOURS OF WORK\\n\\n7.1 Your normal working hours are Monday to Friday from 9.00 am to 5.30 pm on each working day with one hour for lunch. You will be required to work such other hours as shall be reasonably necessary for you to perform your duties for which no further remuneration is payable.\\n\\n7.2 By entering into this Agreement you confirm, that in your capacity as Chief Business Officer you may choose or determine the duration of your working time and the working time limits set out in part II of the Working Time Regulations 1998 do not apply to you.\\n\\n8 HOLIDAYS\\n\\n8.1 In addition to the usual public holidays you will be entitled to 25 working days paid holiday in each calendar year. The holiday will accrue on a pro rata basis throughout each calendar year.\\n\\n8.2 Holidays may only be taken at such time or times as are approved beforehand by the CEO, such approval not to be unreasonably withheld or delayed. You must give reasonable notice of proposed holiday dates by e-mailing the CEO or delegated director in advance, for approval.\\n\\n8.3 The holiday year runs from January to December. With the agreement of the CEO, you may carry forward up to 5 days of untaken holiday into the next holiday year. Any carried over holiday must be taken by the end of March of the following calendar year or will be forfeited and no payment will be made in respect of any days so forfeited. You will not generally be permitted to take more than 10 days holiday at any one time.\\n\\n8.4 Upon termination of your employment you will receive pay in lieu of accrued but untaken holiday. The Company may deduct an appropriate sum in respect of days taken in excess of your pro rata entitlement from your final remuneration on the basis that one day's holiday will be calculated as 1/260ths of your basic annual salary.\\n\\n8.5 In the event that notice of termination of this Agreement is served by either party, the Company may require you to take any outstanding holiday during this notice period.\\n\\n4\\n\\n\\n\\n\\n\\n9 SICKNESS AND OTHER ABSENCE\\n\\n9.1 If you are unable to attend at work by reason of sickness or injury or any unauthorised reason you must inform the Company as soon as possible on the first day of absence (and in any event not later than 11.00 am on the first day of absence) and, in the case of absence of uncertain duration, you must keep the Company regularly informed of your continued absence and your likely date of return. You are expected to observe this rule very strictly since failure to do so will entitle the Company to stop payment in respect of each day you fail to notify the Company.\\n\\n9.2 If your absence, due to sickness or injury, is for less than seven (7) days, on your return to work you are required to immediately complete a self-certification form available from the Company. If your absence continues for more than seven (7) consecutive days (whether or not working days) you must provide the Company with a doctor's certificate from the seventh consecutive day of sickness or injury. This doctor's certificate must be provided to the Company promptly following the seventh consecutive day of absence. If illness continues after the expiry of the first certificate, further certificates must be provided promptly to cover the whole period of absence.\\n\\n9.3 Subject to your compliance with the Company's sickness absence procedures (as amended from time to time), the Company may in its sole and absolute discretion pay full salary and contractual benefits during any period of absence due to sickness or injury for up to an aggregate of 3 months in any fifty-two (52) week period (whether such absence is continuous or intermittent in any calendar year). Such payment shall be inclusive of any statutory sick pay due in accordance with applicable legislation in force at the time of absence. The Company may, in its sole and absolute discretion, extend the period of allowance in an individual case if the circumstances so justify. Thereafter, the Company shall pay statutory sick pay or equivalent benefit to which you may be entitled subject to your compliance with the appropriate rules.\\n\\n9.4 Whether absent from work or not, you may be, but only on reasonable grounds, required to undergo a medical examination by a Company doctor and your consent will be sought for a report to be sent to the Company.\\n\\n9.5 The payment of sick pay in accordance with this paragraph 9 is without prejudice to the Company's right to terminate this Agreement prior to the expiry of your right to payments.\\n\\n9.6 In the event you are incapable of performing your duties by reason of injuries sustained wholly or partly as a result of a third party's actions all payments made to you by the Company as salary or sick pay shall to the extent that compensation is recoverable from that third party constitute loans to you and shall be due and owing when and to the extent that you recover compensation for loss of earnings from the third party.\\n\\n10 GARDEN LEAVE\\n\\n10.1 After notice of termination has been given by you or the Company, the Company may at its discretion require you, for all or part of your notice period, to comply with any or all of the following instructions:\\n\\n(a) not to carry out any further work for the Company or for any Group Company;\\n\\n(b) to remain away from the Company's business premises and those of any Group\\n\\n5\\n\\n\\n\\n\\n\\nCompany (unless given written permission to do otherwise);\\n\\n(c) not to contact any of the Company's clients, suppliers or employees or those of any Group Company without the Company's prior written permission;\\n\\n(d) to carry out only part of your duties, or to carry out alternative duties or special projects for the Company within your skill set;\\n\\n(e) to co-operate in the handover of your duties and responsibilities;\\n\\n(f) to resign from any offices (including as a director) you hold within the Company or any Group Company or by virtue of your employment with us;\\n\\n(g) to answer, in an honest and helpful way, such questions as the Company may reasonably ask of you;\\n\\n(h) to keep the Company informed of your whereabouts and contact details and to remain reasonably contactable and available for work.\\n\\n10.2 During any such period as described in paragraph 10.1 (\\\"Garden Leave\\\") the Company may appoint another person to carry out some or all of your duties. You will continue to owe all other duties and obligations (whether express or implied including fidelity and good faith) during Garden Leave and you shall continue to receive full pay and benefits (except that you will not accrue any further entitlement to any cash or equity incentive awards or bonus payments in respect of the Garden Leave period).\\n\\n10.3 By placing you on Garden Leave, the Company will not be in breach of this Agreement or any implied duty of any kind whatsoever nor will you have any claim against the Company in respect of any such action.\\n\\n10.4 During any period of Garden Leave you will remain readily contactable and available for work save when on paid holiday taken in accordance with paragraph 8. In the event that you are not available for work having been requested by the Company to do so, you will, notwithstanding any other provision of this Agreement, forfeit any right to salary and contractual benefits.\\n\\n10.5 During any period of Garden Leave the Company may require you to deliver up any Confidential Information or property of the Company or any Group Company and upon instruction, delete any emails, spreadsheets or other Confidential Information and you will confirm your compliance with this paragraph 10.5 in writing if requested to do so by the Company.\\n\\n10.6 During any period of Garden Leave the Company may require you to take any outstanding holiday entitlement.\\n\\n11 NOTICE\\n\\n11.1 Without prejudice to the Company's right to summarily terminate your employment in accordance with paragraph 11.3 below and your right to summarily terminate your employment for Good Reason in accordance with paragraph 11.4 below, either you or the Company may terminate your employment by giving to the other not less than six months' notice in writing.\\n\\n11.2 The Company reserves the right in its sole and absolute discretion to give written notice to\\n\\n6\\n\\n\\n\\n\\n\\nterminate your employment forthwith and to make a payment to you in lieu of salary and the benefits set out in paragraph 5 of this Agreement for all or any unexpired part of the notice period. For the avoidance of doubt, any payment in lieu made pursuant to this paragraph 11.2 will not include any element in relation to any payment in respect of (i) any Annual Performance Bonus or (ii) any holiday entitlement that would have otherwise accrued during the period for which the payment in lieu is made. For the further avoidance of doubt, if the Company elects to make a Payment in Lieu after notice of termination has been given by you, this will not constitute a termination by the Company without Cause for the purposes of paragraphs 11.7 and 11.8 below.\\n\\n11.3 The Company may summarily terminate your employment hereunder (without notice) for Cause. For purposes of this Agreement, \\\"Cause\\\" shall mean where you:\\n\\n(a) commit gross misconduct which includes, but is not limited to, dishonesty, fraud, theft, being under the influence of alcohol or drugs at work, causing actual or threatening physical harm and causing damage to Company property;\\n\\n(b) commit a material breach or non-observance of your duties or any of the provisions of this Agreement, or materially fail to observe the lawful directions of the Company, or breach any material Company policy or code of conduct, including but not limited to the Company's policy from time to time on matters relating to harassment;\\n\\n(c) are convicted of a criminal offence (other than an offence under the road traffic legislation in the United Kingdom or elsewhere for which a non-custodial sentence is imposed);\\n\\n(d) act in a manner which in the reasonable opinion of the Company, brings the Company into disrepute or otherwise prejudices or is in the reasonable opinion of the Company considered likely to prejudice the reputation of the Company;\\n\\n(e) in the reasonable opinion of the Company, are guilty of any serious negligence in connection with or affecting the business or affairs of the Company;\\n\\n(f) are unfit to carry out the duties hereunder because of sickness, injury or otherwise for an aggregate period of 26 weeks in any fifty-two (52) week period even if, as a result of such termination, you would or might forfeit any entitlement to benefit from sick pay under paragraph 9.3 above.\\n\\nAny delay or forbearance by the Company in exercising any right of termination in accordance with this paragraph 11.3 will not constitute a waiver of such right.\\n\\n11.4 You may summarily terminate your employment hereunder at any time (without notice) for Good Reason after complying with the Good Reason Process. For purposes of this Agreement, \\\"Good Reason\\\" shall mean that you have complied with the \\\"Good Reason Process\\\" (hereinafter defined) following the occurrence of any of the following events: (i) a material diminution in your responsibilities, authority or duties; (ii) a material diminution in your Salary; (iii) a material change in the geographic location at which you provides services to the Company; or (iv) the material breach of this Agreement by the Company. \\\"Good Reason Process\\\" shall mean that (i) you reasonably determine in good faith that a \\\"Good Reason\\\" condition has occurred; (ii) you notify the Company in writing of the first occurrence of the Good\\n\\n7\\n\\n\\n\\n\\n\\nReason condition within 60 days of the first occurrence of such condition; (iii) you cooperate in good faith with the Company's efforts, for a period not less than 30 days following such notice (the \\\"Cure Period\\\"), to remedy the condition; (iv) notwithstanding such efforts, the Good Reason condition continues to exist; and (v) you terminate your employment (without notice) within 60 days after the end of the Cure Period. If the Company cures the Good Reason condition during the Cure Period, Good Reason shall be deemed not to have occurred.\\n\\n11.5 Your employment hereunder shall also terminate immediately upon your death.\\n\\n11.6 If your employment with the Company is terminated for any reason, the Company shall pay or provide to you (or to your authorised representative or estate) (i) any Salary earned through the Termination Date (as defined below); (ii) unpaid expense reimbursements (subject to, and in accordance with, paragraph 6 of this Agreement); and (iii) any vested benefits you may have under any employee benefit plan of the Company through the Termination Date, which vested benefits shall be paid and/or provided in accordance with the terms of such employee benefit plans (collectively, the \\\"Accrued Benefits\\\").\\n\\nSeverance Pay and Benefits Upon Termination by the Company without Cause or by the Executive for Good Reason outside the Change in Control Period.\\n\\n11.7 If your employment is terminated on account of your death or by the Company without Cause (being for any reason not covered by paragraph 11.3), or you terminate your employment for Good Reason (as provided in paragraph 11.4), in either case outside of the Change in Control Period, then the Company shall pay you the Accrued Benefits. In addition, subject to (i) your (or your authorised representative or estate signing, if the termination is due to your death) signing a settlement agreement and a separation agreement and release (together the \\\"Settlement Agreements\\\") in a form and manner satisfactory to the Company, which shall include, without limitation, a general release of claims against the Company and all related persons and entities, a reaffirmation of all of your continuing obligations to the Company, including those set forth in paragraphs 13 - 15, and (in the case of the separation agreement and release) and a seven (7) business day revocation period; and (ii) the separation agreement and release becoming irrevocable, all within 60 days after the Termination Date (or such shorter period as set forth in the Settlement Agreements), the Company shall: (A) pay you (or your authorised representative or estate if the termination is due to your death) an amount equal to nine (9) months of your salary as of the Termination Date (which payment shall not be reduced by either the value of any salary paid to you during your notice period or by any payment in lieu of notice made pursuant to paragraph 11.2); and (B) pay you (or your authorised representative or estate if the termination is due to your death) an amount equal to the cost to the Company of providing you with the contractual benefits under paragraph 5 for nine (9) months or, at the Company's option, continue to provide you with such benefits for nine (9) months.\\n\\nSeverance Pay and Benefits Upon Termination by the Company without Cause or by the Executive for Good Reason Within the Change in Control Period\\n\\n11.8 The provisions of this paragraph 11.8 shall apply in lieu of, and expressly supersede, the provisions of paragraph 11.7 regarding severance pay and benefits upon a termination by the Company without Cause or by you for Good Reason if such termination of employment occurs within 12 months after the occurrence of the first event constituting a Change in Control (such period, the \\\"Change in Control Period\\\"). These provisions shall terminate and be of no further\\n\\n8\\n\\n\\n\\n\\n\\nforce or effect after the Change in Control Period.\\n\\n(a) Change in Control Period. If during the Change in Control Period your employment is terminated on account of your death or by the Company without Cause (being for any reason not covered by paragraph 11.3) or you terminate your employment for Good Reason (as provided in paragraph 11.4), then, subject to (i) your signing (or your authorised representative or estate signing, if the termination is due to your death) a settlement agreement and a separation agreement and release (together the Settlement Agreements) in a form and manner satisfactory to the Company, which shall include, without limitation, a general release of claims against the Company and all related persons and entities, a reaffirmation of all of your continuing obligations to the Company, including those set forth in paragraphs 13 - 15, and (in the case of the separation agreement and release) and a seven (7) business day revocation period; and (ii) the separation agreement and release becoming irrevocable, all within 60 days after the Termination Date (or such shorter period as set forth in the Settlement Agreements):\\n\\n(i) the Company shall pay you (or your authorised representative or estate if the termination is due to your death) an amount equal to the sum of (A) your annual salary as of the Termination Date (or your annual salary in effect immediately prior to the Change in Control, if higher) plus (B) your target annual performance bonus amount under the Annual Bonus Plan for the then-current year (the \\\"Change in Control Payment\\\"), which payment shall not be reduced by either the value of any salary paid to you during your notice period or by the value of any payment made to you in lieu of notice pursuant to paragraph 11.2;\\n\\n(ii) the Company shall: pay you (or your authorised representative or estate if the termination is due to your death) an amount equal to the cost to the Company of providing you with the contractual benefits under paragraph 5 for twelve (12) months or, at the Company's option, continue to provide you with such benefits for twelve (12) months; and\\n\\n(iii) notwithstanding anything to the contrary in any applicable option agreement or other stock-based award agreement, all Time-Based Equity Awards shall immediately accelerate and become fully exercisable (for a period determined in accordance with the rules of the applicable equity plan) or nonforfeitable as of the later of (A) the Termination Date or (B) the Accelerated Vesting Date; provided that any termination or forfeiture of the unvested portion of such Time-Based Equity Awards that would otherwise occur on the Termination Date in the absence of this Agreement will be delayed until the Effective Date of the Settlement Agreements and will only occur if the vesting pursuant to this subsection does not occur due to the absence of the Settlement Agreements becoming fully effective within the time period set forth therein. Notwithstanding the foregoing, no additional vesting of the Time-Based Equity Awards shall occur during the period between your Termination Date and the Accelerated Vesting Date.\\n\\n11.9 Definitions. For purposes of this paragraph 11, the following terms shall have the following meanings:\\n\\n9\\n\\n\\n\\n\\n\\n\\\"Accelerated Vesting Date\\\" means the effective date of the Settlement Agreements signed by you (or your authorised representatives or estate if the termination is due to your death).\\n\\n\\\"Termination Date\\\" means the date on which your employment hereunder terminates.\\n\\n\\\"Time-Based Equity Awards\\\" means all time-based stock options and other stock-based awards subject to time based vesting held by you.\\n\\n\\\"Change in Control\\\" has the meaning given to that term in the Schedule to this Agreement.\\n\\n12 DISCIPLINARY, DISMISSAL AND GRIEVANCE PROCEDURES\\n\\n12.1 A copy of the Company's disciplinary, dismissal and grievance procedures are set out in its employee handbook (the \\\"Employee Handbook\\\").\\n\\n12.2 Any grievance concerning your employment should be taken up orally in the first instance with the CEO. If the grievance is not resolved to your satisfaction, you should then refer it to the Chairman.\\n\\n12.3 The Company reserves the right to suspend you on full pay and benefits at any time for a reasonable period to investigate any potential disciplinary matter that it reasonably believes you may be or may have been involved in.\\n\\n13 OUTSIDE EMPLOYMENT, CONFIDENTIAL INFORMATION, CONFLICTING INTERESTS AND RETURN OF COMPANY PROPERTY\\n\\n13.1 For the purposes of this paragraph 13, paragraph 10 above and paragraph 14 below the expression \\\"Confidential Information\\\" shall include, but not be limited to, any and all knowledge, data or information (whether or not recorded in documentary form or on computer disk or tape), which may be imparted in confidence or which is of a confidential nature or which you may reasonably regard as being confidential or a trade secret by the Company, concerning the business, business performance or prospective business, financial information or arrangements, plans or internal affairs of the Company, any Group Company or any of their respective customers. By way of illustration but not limitation, \\\"Confidential Information\\\" includes (a) trade secrets, inventions, mask works, ideas, processes, formulas, software in source or object code, data, records, reports, interpretations, the contents of any databases, programs, other works of authorship, know-how, materials, improvements, discoveries, developments, technical information, designs and techniques and any other proprietary technology and all IPRs (as defined below) therein (collectively, \\\"Inventions\\\"); (b) information regarding research, development, new products, planned products, planned surveys, marketing surveys, research reports, market share and pricing statistics, marketing and selling, business plans, financial details, budgets and unpublished financial statements, licenses, prices and costs, fee levels, margins, discounts, credit terms, pricing and billing policies, quoting procedures, commissions, commission charges, other price sensitive information, methods of obtaining business and other business methods, forecasts, future plans and potential strategies, financial projections and business strategies and targets, operational plans, financing and capital-raising plans, activities and agreements, internal services and operational manuals, methods of conducting Company business, corporate and business accounts, suppliers and supplier information, and purchasing; (c) information regarding clients or customers and potential clients or customers of the Company, including customer lists, client\\n\\n10\\n\\n\\n\\n\\n\\nlists, names, addresses (including email), telephone, facsimile or other contact numbers and contact names, representatives, their needs or desires with respect to the types of products or services offered by the Company, proposals, bids, contracts and their contents and parties, the type and quantity of products and services provided or sought to be provided to customers and potential customers of the Company and other non-public information relating to customers and potential customers; (d) information regarding any of the Company's business partners and their services, including names, representatives, proposals, bids, contracts and their contents and parties, the type and quantity of products and services received by the Company, and other non-public information relating to business partners; (e) information regarding personnel, computer passwords, employee lists, compensation and remuneration, and employee skills; and (f) any other non-public information which a competitor of the Company could use to the competitive disadvantage of the Company.\\n\\n13.2 You shall not, without the prior written consent of the Company, either solely or jointly, directly or indirectly, carry on or be engaged, concerned or interested in any other trade or business, including, but not limited to, carrying on business with the Company's suppliers or dealers, save that nothing in this paragraph 13.2 shall prevent you from holding (with the prior written consent of the Company, which shall not be unreasonably delayed or withheld) up to three percent (3%) of the issued equity share capital of any company where those equity shares are listed on a recognised investment exchange (as defined in section 285 of the Financial Services and Markets Act 2000) or traded on the AIM market operated by the London Stock Exchange. Failure to secure advance permission in accordance with this paragraph 13.2 may result in summary dismissal.\\n\\n13.3 You will not (except with the prior written consent of the Board) except in the proper course of your duties during the continuance of this Agreement (which for the avoidance of doubt shall include the use of laptops and remote working), or at any time thereafter:\\n\\n(a) disclose or use for your own or for another's purpose or benefit any Confidential Information which you may learn while in the employment of the Company except as required by a court of law or any regulatory body or that which may be in or become part of the public domain other than through any act or default on your part;\\n\\n(b) copy or reproduce in any form or by or on any media or device or allow others access to copy or reproduce any documents (including without limitation letters, facsimiles and memoranda), disks, memory devices, notebooks, tapes or other medium whether or not eye-readable and copies thereof on which Confidential Information may from time to time be recorded or referred to (\\\"Documents\\\"); or\\n\\n(c) remove or transmit from the Company or any Group Company's premises any Documents on which Confidential information may from time to time be recorded.\\n\\n13.4 Upon termination of your employment for any reason by either party, you must immediately return to the Company all Company property including but not limited to documents, papers, records, keys, credit cards, mobile telephones, computer and related equipment, PDA or similar device, security passes, accounts, specifications, drawings, lists, correspondence, catalogues or the like relating to the Company's business which is in your possession or under your control and you must not take copies of the same without the Company's express written authority.\\n\\n11\\n\\n\\n\\n\\n\\n14 RESTRICTIVE COVENANTS\\n\\n14.1 For the purpose of this paragraph 14 the following expressions shall have the following meanings:\\n\\n\\\"Prospective Customer\\\" shall mean any person, firm, company or other business who was to your knowledge at the Termination Date negotiating with the Company or with any Group Company with a view to dealing with the Company or any Group Company as a customer;\\n\\n\\\"Restricted Business\\\" means any business which (i) carries on research in the field of constrained peptides, including, without limitation, all work in the field of lead constrained peptide identification and optimization and pre-clinical development of constrained peptide therapeutics or (ii) is developing a drug conjugate compound for treating cancer that targets the same target as a drug conjugate compound in development by any Group Company;\\n\\n\\\"Restricted Customers\\\" shall mean any person, firm, company or other business who was to your knowledge at any time in the twelve (12) month period ending with the Termination Date a customer of the Company or any Group Company;\\n\\n\\\"Restricted Period\\\" shall mean the period of twelve (12) months from the Termination Date;\\n\\n\\\"Restricted Territory\\\" means anywhere in the United States or the United Kingdom or in any other country in which the Company or any Group Company conducts business or as of the date of termination of my employment relationship had plans to conduct business; and\\n\\n\\\"Termination Date\\\" shall mean the date on which your employment under this Agreement terminates either due to you or the Company terminating it in accordance with the terms of the Agreement or in breach of the terms of this Agreement.\\n\\n14.2 During the course of your employment hereunder you are likely to obtain Confidential Information relating to the business of the Company or any Group Company and personal knowledge and influence over clients, customers and employees of the Company or any Group Company. You hereby agree with the Company that to protect the Company's and any and all Group Company's business interests, customer connections and goodwill and the stability of its or their workforce, that you will not during the Restricted Period (and in respect of sub-paragraph 14.2(f) below only, at any time):\\n\\n(a) in the Restricted Territory, compete with the business of the Company or any Group Company by being directly or indirectly employed or engaged in any capacity by any person, firm or company which engages in or provides Restricted Business or commercial activities competitive with the Restricted Business to Restricted Customers or Prospective Customers;\\n\\n(b) in the Restricted Territory, compete with the business of the Company or any Group Company either on your own account or for any person, firm or company directly or indirectly by transacting business in competition with the Restricted Business with any Restricted Customer or Prospective Customer of the Company or Group Company and with whom you personally dealt in respect of Restricted Business in the pursuance of the employment hereunder in the twelve (12) months prior to the Termination Date;\\n\\n12\\n\\n\\n\\n\\n\\n(c) in the Restricted Territory, compete with the business of the Company or any Group Company either on your own account or for any person, firm or company directly or indirectly in competition with the Restricted Business by soliciting or endeavouring to solicit or entice the business or custom of any Restricted Customer or Prospective Customer and with whom you personally dealt in respect of Restricted Business in the pursuance of the employment hereunder in the twelve (12) months prior to the Termination Date;\\n\\n(d) either on your own account or for any person, firm or company directly or indirectly solicit or entice away or endeavour to solicit or entice away any director or senior employee of the Company or any Group Company employed in a managerial, scientific or technical role with whom you have had material personal dealings in the twelve (12) months prior to the Termination Date;\\n\\n(e) from the Termination Date for the purpose of carrying on any trade, or business represent or allow you to be represented or held out as having any present association with the Company or any Group Company; and\\n\\n(f) from the Termination Date carry on any trade or business whose name incorporates the word Bicycle or any deviation or extension thereof which is likely or which may be confused with the name of the Company or any Group Company.\\n\\n14.3 While the restrictions set out in paragraph 14.2 above are considered by the parties to be reasonable in all the circumstances, it is agreed that if any one or more of such restrictions shall either taken by itself or themselves together be adjudged to go beyond what is reasonable in all the circumstances for the protection of the legitimate interests of the Company but would be adjudged reasonable if any particular restriction or restrictions were deleted or if any part or parts of the wording thereof were deleted, restricted or limited in a particular manner, then the restrictions set out in paragraph 14.2 above shall apply with such deletions or restrictions or limitations as the case may be.\\n\\n14.4 For the avoidance of doubt nothing in this paragraph 14 shall prevent you from having any dealings with any Prospective Customer or Restricted Customer in relation to any business which is not Restricted Businesses and which is not competitive with the Restricted Business, nor from continuing to deal with any Prospective Customer or Restricted Customer where you either have a social or business relationship unconnected to the Company and that relationship does not compete with the Restricted Business.\\n\\n14.5 The restrictions contained in paragraph 14.2 above are held by the Company for itself and on trust for any other Group Company and shall be enforceable by the Company on their behalf or by any Group Company (at their request). You shall during the employment hereunder enter into direct agreements with any Group Company whereby you will accept restrictions in the same or substantially the same form as those contained in paragraph 14.2 above.\\n\\n14.6 In the event that the Company exercises its rights and places you on Garden Leave under paragraph 10 above then the Restricted Period shall be reduced by any period/s spent by you on Garden Leave prior to the Termination Date.\\n\\n14.7 During the Restricted Period you shall provide a copy of the restrictions contained at paragraph 13 above and this paragraph 14 to any employer or prospective employer or any other party\\n\\n13\\n\\n\\n\\n\\n\\nwith whom you become or will become engaged or provide service or services to.\\n\\n15 INTELLECTUAL PROPERTY\\n\\n15.1 For the purpose of this paragraph 15 \\\"IPRs\\\" shall mean all trade secrets, Copyrights, trademarks and trade and business names (including goodwill associated with any trademark or trade or business names and the right to sue for passing off or unfair competition), service marks, mask work rights, patents, petty patents, rights in ideas, concepts, innovations, discoveries, developments and improvements, drug formulations, technology, rights in domain names, rights in inventions, utility models, rights in know-how (including all data, methods, processes, practices and other results of research), unregistered design rights, registered design rights, database rights, semiconductor topography rights and other intellectual property rights recognized by the laws of any jurisdiction or country including all applications and rights to apply for and be granted, renewals or extensions of, and rights to claim priority from, such rights and all similar or equivalent rights or forms of protection which subsist or will subsist now or in the future in any part of the world; the term \\\"Copyright\\\" means the exclusive legal right to reproduce, perform, display, distribute and make derivative works of a work of authorship (as a literary, musical, or artistic work) recognized by the laws of any jurisdiction or country; and the term \\\"Moral Rights\\\" means all paternity, integrity, disclosure, withdrawal, special and any other similar rights recognized by the laws of any jurisdiction or country.\\n\\n15.2 It is contemplated that you may in the course of your employment with the Company create, author or originate (either alone or jointly with others) Inventions (as defined in paragraph 13.1), and/or records, reports, papers, databases, data, information, know how, literature, drawings, graphics, typographical arrangements, designs, works, documents, publications and other materials (in printed, electronic, or any other media or form) (together with Inventions constituting \\\"Works\\\").\\n\\n15.3 You will promptly disclose to the Company full details of any Inventions on their creation and provide further details, explanations and demonstrations as the Company from time to time requests.\\n\\n15.4 All IPRs subsisting in any Works shall be the exclusive property of the Company.\\n\\n15.5 To the extent that such IPRs do not vest automatically in the Company by operation of law, you hereby assign and agree to assign to the Company all of your right, title and interest in any existing and future IPRs which may subsist in any Works for their full term of protection (including any extensions, revivals and renewals) together with the right to sue and claim remedies for past infringement and all materials embodying these rights to the fullest extent permitted by law in any and all countries of the world. Insofar as such IPRs do not vest automatically by operation of law or under this Agreement, the Consultant holds legal title in these rights and inventions on trust for the Company.\\n\\n15.6 To the extent permitted by law you hereby irrevocably and unconditionally waive in favour of the Company, its licensees and successors in title, all existing and future Moral Rights (or similar rights existing in any part of the world) you may have in respect of any Works under Chapter IV of the Copyright Designs and Patents Act 1988 in England or any similar provisions of law in any jurisdiction, including (but without limitation) the right to be identified, the right of integrity and the right against false attribution, and agrees not to institute, support, maintain or\\n\\n14\\n\\n\\n\\n\\n\\npermit any action or claim to the effect that any treatment, exploitation or use of such Works, Inventions or other materials infringes the Consultant's Moral Rights.\\n\\n15.7 Without prejudice to the generality of paragraph 15.9 below, during your employment with the Company and thereafter, without limit in time, you shall at the request and expense of the Company, promptly assist the Company:\\n\\n(a) to file, prosecute, obtain and maintain registrations and applications for registration of any IPRs subsisting in, or protecting, any Works; and\\n\\n(b) to commence and prosecute legal and other proceedings against any third party for infringement of any IPRs subsisting in, or protecting, any Works and to defend any proceedings or claims made by any third party that the use or exploitation of any Works infringes the IPRs or rights of any third party.\\n\\n15.8 You shall keep details of all Inventions confidential and shall not disclose the subject matter of any Inventions to any person outside the Company without the prior consent of the Company. You acknowledge that any unauthorised disclosure of such subject matter may prevent the Company from obtaining patent or registered intellectual property protection for such Invention.\\n\\n15.9 Whenever requested to do so by the Company and in any event on the termination or expiry of this Agreement, you shall promptly deliver to the Company all correspondence, documents, papers and records on all media (and all copies or abstracts of them), recording or relating to any part of the Works and the process of their creation which are in your possession, custody or power.\\n\\n15.10 Subject to paragraph 15.10 below, during your employment with the Company and thereafter without limit in time you shall at the request and expense of the Company promptly execute and do all acts, matters, documents and things necessary or desirable to give the Company the full benefit of the provision of this paragraph 15. You shall not register nor attempt to register any of the IPRs in the Works, nor any of the Inventions, unless requested to do so in writing by the Company.\\n\\n15.11 Nothing in this paragraph 15 shall be construed, or have the effect of, restricting your rights under sections 39 to 43 (inclusive) of the Patents Act 1977 (as amended from time to time).\\n\\n16 LITIGATION ASSISTANCE\\n\\nDuring the term of your employment and at all times thereafter subject always to your obligations to third parties, you shall furnish such information and proper assistance to the Company or any Group Companies as it or they may reasonably require in connection with the Company's intellectual property (including without limitation applying for, defending, maintaining and protecting such intellectual property) and in connection with litigation in which it is or they are or may become a party. This obligation on you shall include, without limitation, meeting with the Company or any Group Companies' legal advisers, providing witness evidence, both in written and oral form, and providing such other assistance that the Company or any Group Companies' legal advisors in their reasonable opinion determine. The Company shall reimburse you for all reasonable out of pocket expenses incurred by you in furnishing such information and assistance and in the event you are no longer employed by the Company a reasonable daily rate (as agreed between you and the Company for such assistance). Such\\n\\n15\\n\\n\\n\\n\\n\\nassistance shall not require you to provide assistance for more than 5 days in any calendar month. For the avoidance of doubt the obligations under this paragraph 16 shall continue notwithstanding the termination of your employment with the Company.\\n\\n17 COLLECTIVE AGREEMENTS\\n\\nThere are no collective agreements which directly affect your terms and conditions of employment.\\n\\n18 DATA PROTECTION\\n\\nProcessing of personal data and our policies\\n\\n18.1 Information relating to an individual (or from which an individual may be identified) is called \\\"personal data\\\".\\n\\n18.2 In processing personal data, we are required to comply with the law on data protection. To help us achieve this, we have produced a privacy notice (\\\"Privacy Notice\\\"). This may be found in the Employee Handbook. You must read this and comply with it in carrying out your work.\\n\\nData protection principles\\n\\n18.3 In complying with the law on data protection, we are required to comply with what are known as data protection principles. These are summarised in our Privacy Notice. In performing your role and carrying out your responsibilities, you must do your best to ensure that we comply with these principles.\\n\\n18.4 A key element of the data protection principles is the duty to ensure that data is processed securely and protected against unauthorised or unlawful processing or loss. Key elements include the following:\\n\\n(a) You must ensure that laptops, memory sticks, phones and other mobile devices are password protected and encrypted. You must not take such devices outside the office without encryption. You must take care of them and keep them secure.\\n\\n(b) You must use strong passwords, changing them when asked and not sharing them with unauthorised colleagues.\\n\\n(c) You must not access other individuals' personal data unless in the course of your work.\\n\\nData breach - and urgent notification\\n\\n18.5 If you discover a data breach, you must notify the Chairman or CFO immediately - and, if practicable, within one hour. Depending on context, you may then need to provide further information on the circumstances of the breach.\\n\\n18.6 A data breach occurs where there is destruction, loss, alteration or unauthorised disclosure of or access to personal data which is being held, stored, transmitted or processed in any way. For example, there is a data breach if our servers are hacked or if you lose a laptop or USB stick or send an email to the wrong person by mistake.\\n\\n16\\n\\n\\n\\n\\n\\n18.7 Failure to notify a breach or to provide information as set out above will be treated seriously and disciplinary action may be taken.\\n\\nWhy we process personal data\\n\\n18.8 For information on the nature of the data we process, why we process it, the legal basis for processing and related matters, please refer to our Privacy Notice. In summary:\\n\\n(a) We process personal data relating to you for the purposes of our business including management, administrative, employment and legal purposes.\\n\\n(b) We monitor our premises and the use of our communication facilities, including using CCTV cameras, monitoring compliance with our data and IT policies, and where non-compliance is suspected, looking in a more targeted way.\\n\\n18.9 The summary above is for information only. We do not, in general, rely on your consent as a legal basis for processing. Agreeing the terms of this Agreement will not constitute your giving consent to our processing of your data.\\n\\n18.10 We reserve the right to amend the documents referred to above from time to time.\\n\\n19 THIRD PARTY RIGHTS\\n\\nSave in respect of any rights conferred by this Agreement on any Group Company (which such Group Company shall be entitled to enforce), a person who is not a party to this Agreement may not under the Contracts (Rights of Third Parties) Act 1999 enforce any of the terms contained within this Agreement.\\n\\n20 DEFINITIONS\\n\\nIn this Agreement:\\n\\n\\\"Group Company\\\" means a subsidiary or affiliate and any other company which is for the time being a holding company of the Company or another subsidiary or affiliate of any such holding company as defined by the Companies Act 2006 (as amended) and \\\"Group Companies\\\" will be interpreted accordingly.\\n\\n21 ENTIRE AGREEMENT\\n\\nThese terms and conditions constitute the entire agreement between the parties and supersede any other agreement whether written or oral previously entered into.\\n\\n22 JURISDICTION AND CHOICE OF LAW\\n\\nThis Agreement shall be governed by and interpreted in accordance with the laws of England and Wales and the parties to this Agreement submit to the exclusive jurisdiction of the Courts of England and Wales in relation to any claim, dispute or matter arising out of or relating to this Agreement.\\n\\n17\\n\\n\\n\\n\\n\\n23 NOTICES\\n\\nAny notices with respect to this Agreement shall be in writing and shall be deemed given if delivered personally (upon receipt), sent by email or sent by first class post addressed, in the case of the Company, to the Company Secretary at its registered office and in your case, addressed to your address last known to the Company.\\n\\n18\\n\\n\\n\\n\\n\\nSchedule\\n\\nDefinitions\\n\\nChange in Control: means and includes each of the following:\\n\\n(a) a Sale; or\\n\\n(b) a Takeover.\\n\\nThe Compensation Committee shall have full and final authority, which shall be exercised in its sole discretion, to determine conclusively whether a Change in Control has occurred pursuant to the above definition, the date of the occurrence of such Change in Control and any incidental matters relating thereto; provided that any such Change in Control also qualifies as a \\\"change in control event\\\" as defined in Section 409A of the United States Internal Revenue Code of 1986, as amended and the regulations and other guidance thereunder and any state law of similar effect, and any exercise of authority in conjunction with a determination of whether a Change in Control is a \\\"change in control event\\\" is consistent with such regulation.\\n\\nControl: shall have the meaning given to that word by Section 719 of the UK Income Tax (Earnings and Pensions) Act 2003 and \\\"Controlled\\\" shall be construed accordingly.\\n\\nSale: the sale of all or substantially all of the assets of BTL.\\n\\nTakeover: circumstances in which any person (or a group of persons acting in concert) (the \\\"Acquiring Person\\\"):\\n\\n(a) obtains Control of BTL as the result of making a general offer to:-\\n\\ni. acquire all of the issued ordinary share capital of BTL, which is made on a condition that, if it is satisfied, the Acquiring Person will have Control of BTL; or\\n\\nii. acquire all of the shares in BTL; or\\n\\n(b) obtains Control of BTL as a result of a compromise or arrangement sanctioned by a court under Section 899 of the UK Companies Act 2006, or sanctioned under any other similar law of another jurisdiction; or\\n\\n(c) becomes bound or entitled under Sections 979 to 985 of the UK Companies Act 2006 (or similar law of another jurisdiction) to acquire shares in BTL; or\\n\\n(d) obtains Control of BTL in any other way, including but not limited to by way of a merger.\\n\\n19\\n\\n\\n\\n\\n\\nTHIS AGREEMENT has been executed and delivered as a deed by or on behalf of the parties on the date written at the top of page 1.\\n\\nExecuted as a Deed by BICYCLETX LIMITED acting by a director:\\n\\n/s/ Kevin Lee (Director) in the presence of: /s/ Phil Jeffrey Witness Name: Phil Jeffrey Witness Address:\\n\\n20\\n\\n\\n\\n\\n\\nExecuted as a Deed by NIGEL CROCKETT:\\n\\n/s/ Nigel Crockett (Nigel Crockett) in the presence of: /s/ Paula Barnes Witness Name: Paula Barnes Witness Address:\\n\\n21\", \"question\": \"Highlight the parts (if any) of this contract related to \\\"Document Name\\\" that should be reviewed by a lawyer. Details: The name of the contract\", \"answer\": \"SERVICE AGREEMENT\"}\n"
     ]
    }
   ],
   "source": [
    "# What the cuad dataset looks like after processing\n",
    "!head -1 $CUAD_DIR/cuad_train.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caacb15",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "```python\n",
    "{\"taskname\": \"cuad\", \"context\": \"Exhibit 10.2 PORTIONS OF THIS EXHIBIT MARKED BY [**] HAVE BEEN OMITTED PURSUANT TO RULE 601(B)(10) OF REGULATION S-K. THE OMITTED INFORMATION IS (I) NOT MATERIAL AND (II) WOULD LIKELY CAUSE COMPETITIVE HARM TO THE REGISTRANT IF PUBLICLY DISCLOSED. EXECUTION VERSION STRATEGIC ALLIANCE AGREEMENT STRATEGIC ALLIANCE AGREEMENT, dated as of December 20, 2019 (as amended, supplemented or otherwise modified from time to time, this \\\"Agreement\\\"), by and among Farids & Co. LLC, a Delaware limited liability company (\\\"Farids\\\"), Edible Arrangements, LLC, a Delaware limited liability company (\\\"EA\\\"), and Rocky Mountain Chocolate Factory, Inc., a Delaware corporation (the \\\"Company\\\"). W I T N E S S E T H: WHEREAS, the Company is an international franchisor, confectionery manufacturer and retail operator; WHEREAS, Farids is a holding company and, together with TF (as defined below), indirectly controls EA; WHEREAS, EA is a US-based franchisor that specializes in fresh fruit arrangements and specialty fruit gift items; WHEREAS, the Company desires to issue and sell,...If the foregoing applies, the Parties shall use all reasonable endeavours to agree within a reasonable time upon any lawful and reasonable  variations to the     18\\n\\n\\n\\n\\n\\n     Agreement which may be necessary in order to achieve, to the greatest extent possible, the same effect as would have been achieved by  the Clause, or the part of the Clause, in question.     22 GOVERNING LAW     22.1 This Agreement is governed by English law.     22.2 The Parties submit to the non-exclusive jurisdiction of the courts of England and Wales.     This Agreement shall come into force on the date given at the beginning of this Agreement.\\n\\n   19\\n\\nSIGNED by\\n\\n   )        )  (name),                     )   a duly authorised signatory of     ) (signature)  SHBV (HONG KONG) LTD            )\\n\\nSIGNED by\\n\\n      )           )  (name),\\n\\n\\n\\n\\n\\n     )\\n\\na duly authorised signatory of     ) (signature)  WASTE2ENERGY GROUP HOLDINGS PLC      )\", \"question\": \"Highlight the parts (if any) of this contract related to \\\"Document Name\\\" that should be reviewed by a lawyer. Details: The name of the contract\",\"answer\": \"STRATEGIC ALLIANCE AGREEMENT, d\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55663c40",
   "metadata": {},
   "source": [
    "We made a `.jsonl` file for each train, validation, and testing split of the cuad data. Every `.jsonl` file contains JSON objects with the fields `taskname,` `context,` `question,` and `answer.` The preprocessing script is called `prompt_learning_cuad_preprocessing.py.`\n",
    "The CUAD dataset comprises a collection of contract-related questions and answers. It consists of various contracts like \"LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGREEMENT\", \"WHITESMOKE, INC_11_08_2011-EX-10.26-PROMOTION AND DISTRIBUTION AGREEMENT\", and \"MetLife, Inc. - Remarketing Agreement.\" Each contract has a title and paragraph associated with it, and each paragraph has several related questions and answers. When we separated the train/validation/test splits, we separated them on the title level. For example, if the training set contains paragraphs and questions about the contract `LIMEENERGYCO_09_09_1999-EX-10-DISTRIBUTOR AGREEMENT`, neither the validation nor test samples will have any questions on this contract. All questions about a specific contract are isolated to one data split.\n",
    "\n",
    " (Like the Financial PhraseBank Dataset, we randomly selected 80% of the questions for training, 10% for validation, and 10% for testing. The process resulted in `69125` test examples, `8952` validation, and `8744` testing examples. The `answer` field was removed from test examples.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc28145",
   "metadata": {},
   "source": [
    "Training on the whole train split could take a lot of time, so we will clip the train set to 1.5k examples for this lab activity and limit the validation dataset to 150 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af842dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "! head -1500 $CUAD_DIR/cuad_train.jsonl > $CUAD_DIR/cuad_short_train.jsonl\n",
    "! head -150 $CUAD_DIR/cuad_val.jsonl > $CUAD_DIR/cuad_short_val.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38dba611",
   "metadata": {},
   "source": [
    "## P-Tuning Model Config Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8d6c35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "\n",
    "# Load the example config file so we can start editing it\n",
    "CONFIG_PATH = os.path.join(WORK_DIR, \"source_code/activity2/conf/megatron_gpt_prompt_learning_config.yaml\")\n",
    "config = OmegaConf.load(CONFIG_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb4a4a4",
   "metadata": {},
   "source": [
    "Set the train and validation dataset in the config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "089d1609",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model.data.train_ds = [f\"{CUAD_DIR}/cuad_short_train.jsonl\"]\n",
    "config.model.data.validation_ds = [f\"{CUAD_DIR}/cuad_short_val.jsonl\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f308cd56",
   "metadata": {},
   "source": [
    "\n",
    "### Prompt Formatting\n",
    "\n",
    "- Add value to:  \n",
    "```bash\n",
    "      \"taskname\": \"\",\n",
    "     \"prompt_template\": \"\",\n",
    "     ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceebd6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model.task_templates = [\n",
    "    {\n",
    "        \"taskname\": \"cuad\",\n",
    "        \"prompt_template\": \"<|VIRTUAL_PROMPT_0|> Context: {context}\\n\\nQuestion: {question}\\n\\nAnswer:{answer}\",\n",
    "        \"total_virtual_tokens\": 15,\n",
    "        \"virtual_token_splits\": [15],\n",
    "        \"truncate_field\": \"context\",\n",
    "        \"answer_only_loss\": True,\n",
    "        \"answer_field\": \"answer\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae87360",
   "metadata": {},
   "source": [
    "### Setting New Tasks\n",
    "\n",
    "You do this by setting the config file's `new_tasks` and `existing_tasks` values. Because we are p-tuning a model with no existing tasks, you should set `existing_tasks=[]` and `new_tasks=[\"cuad\"]` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bb3efa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.model.existing_tasks = []\n",
    "config.model.new_tasks = [\"cuad\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffecee14",
   "metadata": {},
   "source": [
    "### Set The Pre-Trained GPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95a4283f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PretrainedModelInfo(\n",
       " \tpretrained_model_name=megatron_gpt_345m,\n",
       " \tdescription=345M parameter GPT generative Megatron model.,\n",
       " \tlocation=https://api.ngc.nvidia.com/v2/models/nvidia/nemo/megatron_gpt_345m/versions/1/files/megatron_gpt_345m.nemo\n",
       " )]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check what GPT .nemo models we have available on NGC\n",
    "from nemo.collections.nlp.models.language_modeling.megatron_gpt_model import MegatronGPTModel\n",
    "MegatronGPTModel.list_available_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcd19bb",
   "metadata": {},
   "source": [
    "Download the `nemo_gpt1.3B_fp16.nemo` model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "649e26a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1mTQjczmQQTm-TL0lxxfzoq3EEFoKQ2l6&confirm=t\n",
      "To: /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/source_code/nemo_gpt1.3B_fp16.nemo\n",
      "100%|██████████████████████████████████████| 3.02G/3.02G [00:34<00:00, 86.4MB/s]\n"
     ]
    }
   ],
   "source": [
    "gpt_file_name = \"nemo_gpt1.3B_fp16.nemo\"\n",
    "PRETRAINED_MODEL_DIR = os.path.join(WORK_DIR, \"source_code\")\n",
    "\n",
    "# download the nemo_gpt1.3B_fp16.nemo\n",
    "!python3 ../../source_code/megatron-gpt-model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2086d414",
   "metadata": {},
   "source": [
    "- Now that you have a `.nemo` GPT file, please add its path to the prompt learning config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55bccf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set GPT model path on prompt learning config\n",
    "config.model.language_model_path = f'{PRETRAINED_MODEL_DIR}/nemo_gpt1.3B_fp16.nemo'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c4a614c",
   "metadata": {},
   "source": [
    "- Set checkpoint behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "44554069",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.exp_manager.checkpoint_callback_params.save_nemo_on_train_end= True\n",
    "config.exp_manager.checkpoint_callback_params.always_save_nemo= True\n",
    "config.exp_manager.checkpoint_callback_params.save_best_model= True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e75b98",
   "metadata": {},
   "source": [
    "### Setting P-Tuning Specific Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e48ca86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the virtual prompt style to p-tuning (already set by default)\n",
    "config.model.virtual_prompt_style = \"p-tuning\"\n",
    "\n",
    "\n",
    "config.model.p_tuning.dropout = 0.0\n",
    "config.model.p_tuning.num_layers = 2\n",
    "config.model.global_batch_size = 2\n",
    "config.model.micro_batch_size = 1\n",
    "config.model.max_seq_length = 10240  # you can adjust to the squence length"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d29d7b",
   "metadata": {},
   "source": [
    "Let's have a look at all the values you've set in the model config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "511ce438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seed: 1234\n",
      "nemo_path: ${name}.nemo\n",
      "virtual_prompt_style: p-tuning\n",
      "tensor_model_parallel_size: 1\n",
      "pipeline_model_parallel_size: 1\n",
      "global_batch_size: 2\n",
      "micro_batch_size: 1\n",
      "validation_global_batch_size: ${model.global_batch_size}\n",
      "validation_micro_batch_size: ${model.micro_batch_size}\n",
      "validation_drop_last: false\n",
      "restore_path: null\n",
      "language_model_path: ../../source_code/nemo_gpt1.3B_fp16.nemo\n",
      "save_nemo_on_validation_end: true\n",
      "existing_tasks: []\n",
      "new_tasks:\n",
      "- cuad\n",
      "sequence_parallel: false\n",
      "activations_checkpoint_granularity: null\n",
      "activations_checkpoint_method: null\n",
      "activations_checkpoint_num_layers: null\n",
      "task_templates:\n",
      "- taskname: cuad\n",
      "  prompt_template: '<|VIRTUAL_PROMPT_0|> Context: {context}\n",
      "\n",
      "\n",
      "    Question: {question}\n",
      "\n",
      "\n",
      "    Answer:{answer}'\n",
      "  total_virtual_tokens: 15\n",
      "  virtual_token_splits:\n",
      "  - 15\n",
      "  truncate_field: context\n",
      "  answer_only_loss: true\n",
      "  answer_field: answer\n",
      "prompt_tuning:\n",
      "  new_prompt_init_methods:\n",
      "  - text\n",
      "  new_prompt_init_text:\n",
      "  - some init text goes here\n",
      "p_tuning:\n",
      "  encoder_type: tpmlp\n",
      "  dropout: 0.0\n",
      "  num_layers: 2\n",
      "  encoder_hidden: 2048\n",
      "  init_std: 0.023\n",
      "data:\n",
      "  train_ds:\n",
      "  - ../../data/cuad/cuad_short_train.jsonl\n",
      "  validation_ds:\n",
      "  - ../../data/cuad/cuad_short_val.jsonl\n",
      "  add_eos: true\n",
      "  shuffle: true\n",
      "  num_workers: 8\n",
      "  pin_memory: true\n",
      "  train_cache_data_path: null\n",
      "  validation_cache_data_path: null\n",
      "  test_cache_data_path: null\n",
      "  load_cache: false\n",
      "  max_seq_length: 1024\n",
      "  min_seq_length: 1\n",
      "optim:\n",
      "  name: fused_adam\n",
      "  lr: 0.0001\n",
      "  weight_decay: 0.01\n",
      "  betas:\n",
      "  - 0.9\n",
      "  - 0.98\n",
      "  sched:\n",
      "    name: CosineAnnealing\n",
      "    warmup_steps: 50\n",
      "    min_lr: 0.0\n",
      "    constant_steps: 0\n",
      "    monitor: val_loss\n",
      "    reduce_on_plateau: false\n",
      "max_seq_length: 10240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Final model config\n",
    "print(OmegaConf.to_yaml(config.model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f4dce1",
   "metadata": {},
   "source": [
    "## Building the PyTorch Lightning Trainer\n",
    "\n",
    "*Tips:* \n",
    "- *Check the Multitask Prompt-tuning and P-tuning notebook*\n",
    "- *Set the `config.trainer.max_epochs` to values from 1 to 5 (each epoch takes approximately 7mins running on an A100 MIG instance (32GB))*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52bd41de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit None Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainer config - \n",
      "\n",
      "devices: 1\n",
      "accelerator: gpu\n",
      "num_nodes: 1\n",
      "precision: 16\n",
      "logger: false\n",
      "enable_checkpointing: false\n",
      "replace_sampler_ddp: false\n",
      "max_epochs: 5\n",
      "max_steps: -1\n",
      "log_every_n_steps: 10\n",
      "val_check_interval: 1.0\n",
      "gradient_clip_val: 1.0\n",
      "resume_from_checkpoint: null\n",
      "benchmark: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from nemo.collections.nlp.parts.nlp_overrides import NLPDDPStrategy\n",
    "from pytorch_lightning.plugins.environments import TorchElasticEnvironment\n",
    "\n",
    "# let's modify some trainer configs\n",
    "# check if we have GPU available and uses it\n",
    "accelerator = 'gpu' if torch.cuda.is_available() else 'cpu'\n",
    "config.trainer.accelerator = accelerator\n",
    "config.trainer.devices = 1\n",
    "\n",
    "####### Set from 5 to 10 epochs. Each epoch takes approximately 7mins running on A100 MIG instance(32GB) ########\n",
    "config.trainer.max_epochs = 5  \n",
    "##########################################################################################################\n",
    "config.trainer.val_check_interval = 1.0\n",
    "\n",
    "# for PyTorch Native AMP set precision=16\n",
    "config.trainer.precision = 16 if torch.cuda.is_available() else 32\n",
    "\n",
    "# setup cluster environment parameters\"\n",
    "# use torch elastic cluster environment so `create_process_externally` is True\n",
    "# the launcher is set to None. It will not try to spawn new processes.\n",
    "# It won't create the misconfiguration error because of the `interactive session`\n",
    "os.environ[\"LOCAL_RANK\"] = '0'\n",
    "os.environ[\"RANK\"] = '0'\n",
    "os.environ[\"WORLD_SIZE\"] = '1'\n",
    "\n",
    "strategy = NLPDDPStrategy(find_unused_parameters=False,no_ddp_communication_hook=True)\n",
    "plugins = [TorchElasticEnvironment()]\n",
    "trainer = pl.Trainer(plugins= plugins, strategy=strategy, **config.trainer)\n",
    "\n",
    "print(\"Trainer config - \\n\")\n",
    "print(OmegaConf.to_yaml(config.trainer))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44f4076e",
   "metadata": {},
   "source": [
    "## Setting up a NeMo Experiment\n",
    "\n",
    "NeMo has an experiment manager that handles logging and checkpointing for us, so let's use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0659a7b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:41:17 exp_manager:374] Experiments will be logged at /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17\n",
      "[NeMo I 2024-03-06 10:41:17 exp_manager:797] TensorboardLogger has been set up\n",
      "/net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17\n"
     ]
    }
   ],
   "source": [
    "from nemo.utils.exp_manager import exp_manager\n",
    "\n",
    "# Set name of the experiment\n",
    "config.name = 'p_tuning'\n",
    "config.exp_manager.resume_if_exists = False\n",
    "# Init the experiment manager and view the exp_dir\n",
    "exp_dir = exp_manager(trainer, config.get(\"exp_manager\", None))\n",
    "exp_dir = str(exp_dir)\n",
    "print(exp_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0862cd84",
   "metadata": {},
   "source": [
    "Set the learning rate and the precision values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "974a95df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set some of the learning parameters\n",
    "config.model.optim.lr = 1e-4\n",
    "config.model.precision = config.trainer.precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2915dc",
   "metadata": {},
   "source": [
    "## P-Tuning Session\n",
    "\n",
    "The only thing left is to load up the model and begin p-tuning!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "faf12308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:41:35 megatron_init:234] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2024-03-06 10:41:35 megatron_init:237] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 10:41:35 megatron_init:238] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2024-03-06 10:41:35 megatron_init:246] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2024-03-06 10:41:35 megatron_init:247] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 10:41:35 megatron_init:257] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2024-03-06 10:41:35 megatron_init:261] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 10:41:35 megatron_init:262] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2024-03-06 10:41:35 megatron_init:276] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2024-03-06 10:41:35 megatron_init:288] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2024-03-06 10:41:35 megatron_init:294] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 10:41:35 megatron_init:295] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2024-03-06 10:41:35 megatron_init:296] All embedding group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 10:41:35 megatron_init:297] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2024-03-06 10:42:15 megatron_init:234] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2024-03-06 10:42:15 megatron_init:237] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 10:42:15 megatron_init:238] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2024-03-06 10:42:15 megatron_init:246] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2024-03-06 10:42:15 megatron_init:247] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 10:42:15 megatron_init:257] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2024-03-06 10:42:15 megatron_init:261] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 10:42:15 megatron_init:262] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2024-03-06 10:42:15 megatron_init:276] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2024-03-06 10:42:15 megatron_init:288] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2024-03-06 10:42:15 megatron_init:294] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 10:42:15 megatron_init:295] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2024-03-06 10:42:15 megatron_init:296] All embedding group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 10:42:15 megatron_init:297] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2024-03-06 10:42:15 tokenizer_utils:204] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: None, and merges file: None\n",
      "[NeMo I 2024-03-06 10:42:15 megatron_utils:210] Downloading from https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json\n",
      "[NeMo I 2024-03-06 10:42:16 megatron_utils:210] Downloading from https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt\n",
      "[NeMo I 2024-03-06 10:42:17 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /net/people/tutorial/tutorial057/.cache/torch/megatron/megatron-gpt-345m_vocab, merges_files: /net/people/tutorial/tutorial057/.cache/torch/megatron/megatron-gpt-345m_merges, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:42:17 megatron_base_model:264] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.\n",
      "[NeMo I 2024-03-06 10:42:20 nlp_overrides:401] Model MegatronGPTModel was successfully restored from /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/source_code/nemo_gpt1.3B_fp16.nemo.\n",
      "[NeMo I 2024-03-06 10:42:20 auto_tokenizer:172] 15 special tokens added, resize your model accordingly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:43:00 megatron_init:234] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2024-03-06 10:43:00 megatron_init:237] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 10:43:00 megatron_init:238] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2024-03-06 10:43:00 megatron_init:246] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2024-03-06 10:43:00 megatron_init:247] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 10:43:00 megatron_init:257] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2024-03-06 10:43:00 megatron_init:261] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 10:43:00 megatron_init:262] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2024-03-06 10:43:00 megatron_init:276] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2024-03-06 10:43:00 megatron_init:288] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2024-03-06 10:43:00 megatron_init:294] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 10:43:00 megatron_init:295] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2024-03-06 10:43:00 megatron_init:296] All embedding group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 10:43:00 megatron_init:297] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2024-03-06 10:43:00 tokenizer_utils:204] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: None, and merges file: None\n",
      "[NeMo I 2024-03-06 10:43:00 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /net/people/tutorial/tutorial057/.cache/torch/megatron/megatron-gpt-345m_vocab, merges_files: /net/people/tutorial/tutorial057/.cache/torch/megatron/megatron-gpt-345m_merges, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:43:00 megatron_base_model:264] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.\n",
      "[NeMo I 2024-03-06 10:43:03 nlp_overrides:401] Model MegatronGPTModel was successfully restored from /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/source_code/nemo_gpt1.3B_fp16.nemo.\n",
      "[NeMo I 2024-03-06 10:43:03 auto_tokenizer:172] 15 special tokens added, resize your model accordingly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "from nemo.collections.nlp.models.language_modeling.megatron_gpt_prompt_learning_model import MegatronGPTPromptLearningModel\n",
    "\n",
    "model = MegatronGPTPromptLearningModel(cfg=config.model,trainer=trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a769b3f4",
   "metadata": {},
   "source": [
    "Note: Each training epoch takes around 7 mins but may vary based on the device used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d6c08ae8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "----------------------------------------------------------------------------------------------------\n",
      "distributed_backend=nccl\n",
      "All distributed processes registered. Starting with 1 processes\n",
      "----------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:45:52 gpt_prompt_learning_dataset:85] Loading and tokenizing dataset ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "995291bed7e24a8c892ab52cd46c0980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:45:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:45:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:46:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:47:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:05 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:06 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:07 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:08 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:09 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:10 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:11 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:12 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:13 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:14 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:15 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:16 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:17 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:18 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:19 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:20 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:21 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:22 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:23 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:24 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:25 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:26 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:27 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:28 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:29 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:30 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:31 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:32 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:33 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:34 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:35 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:36 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:37 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:38 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:39 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:40 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:41 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:42 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:43 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:44 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:45 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:46 gpt_prompt_learning_dataset:196] Skipped 0 sentences, sequence length too short or too long even after truncation\n",
      "[NeMo I 2024-03-06 10:48:46 gpt_prompt_learning_dataset:85] Loading and tokenizing dataset ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1347fb395da4868bfacce2bddf16a14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:48:46 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:47 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:48 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:49 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:50 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:51 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:52 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:53 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:54 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:55 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:58 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:48:59 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:00 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:01 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:02 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:03 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:04 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 10:49:04 gpt_prompt_learning_dataset:196] Skipped 0 sentences, sequence length too short or too long even after truncation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:49:05 nlp_overrides:124] Configuring DDP for model parallelism.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-03-06 10:49:05 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/apex/optimizers/fused_adam.py:112: UserWarning: The torch.cuda.*DtypeTensor constructors are no longer recommended. It's best to use methods such as torch.tensor(data, dtype=*, device='cuda') to create tensors. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/tensor/python_tensor.cpp:82.)\n",
      "      self._dummy_overflow_buf = torch.cuda.IntTensor([0])\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:49:05 modelPT:721] Optimizer config = FusedAdam (\n",
      "    Parameter Group 0\n",
      "        betas: [0.9, 0.98]\n",
      "        bias_correction: True\n",
      "        eps: 1e-08\n",
      "        lr: 0.0001\n",
      "        weight_decay: 0.01\n",
      "    )\n",
      "[NeMo I 2024-03-06 10:49:05 lr_scheduler:910] Scheduler \"<nemo.core.optim.lr_scheduler.CosineAnnealing object at 0x1542163fedd0>\" \n",
      "    will be used during training (effective maximum steps = 3750) - \n",
      "    Parameters : \n",
      "    (warmup_steps: 50\n",
      "    min_lr: 0.0\n",
      "    constant_steps: 0\n",
      "    max_steps: 3750\n",
      "    )\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type                   | Params\n",
      "-----------------------------------------------------------\n",
      "0 | frozen_model    | MegatronGPTModel       | 812 M \n",
      "1 | word_embeddings | VocabParallelEmbedding | 103 M \n",
      "2 | prompt_encoder  | PromptEncoder          | 8.5 M \n",
      "-----------------------------------------------------------\n",
      "8.4 M     Trainable params\n",
      "812 M     Non-trainable params\n",
      "820 M     Total params\n",
      "1,641.669 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12f89113b7c74aa7a9d91a77dc02c275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-03-06 10:49:05 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/dataloader/evaluation_loop.py:401: UserWarning: Found `dataloader_iter` argument in the `validation_step`. Note that the support for this signature is experimental and the behavior is subject to change.\n",
      "      rank_zero_warn(\n",
      "    \n",
      "[NeMo W 2024-03-06 10:49:05 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/apex/transformer/pipeline_parallel/utils.py:81: UserWarning: This function is only for unittest\n",
      "      warnings.warn(\"This function is only for unittest\")\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:49:08 megatron_gpt_prompt_learning_model:440] val_loss: 4.312137126922607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-03-06 10:49:08 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:536: PossibleUserWarning: It is recommended to use `self.log('val_loss', ..., sync_dist=True)` when logging on epoch level in distributed setting to accumulate the metric across devices.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "[NeMo W 2024-03-06 10:49:08 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/loops/fit_loop.py:344: UserWarning: Found `dataloader_iter` argument in the `training_step`. Note that the support for this signature is experimental and the behavior is subject to change.\n",
      "      rank_zero_warn(\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d9be64179b447a494e4c11e5e14b8b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-03-06 10:49:11 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/logger_connector/result.py:232: UserWarning: You called `self.log('global_step', ...)` in your `training_step` but the value needs to be floating point. Converting it to torch.float32.\n",
      "      warning_cache.warn(\n",
      "    \n",
      "[NeMo W 2024-03-06 10:49:11 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "      warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n",
      "    \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b68f924785c4e43b6e76b97d1b7fd5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:50:55 megatron_gpt_prompt_learning_model:440] val_loss: 1.6131223440170288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 750: 'val_loss' reached 1.61312 (best 1.61312), saving model to '/net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/megatron_gpt_prompt_tune--val_loss=1.613-step=750.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:50:56 nemo_model_checkpoint:168] New best .nemo model saved to: /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/p_tuning.nemo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved. New best score: 1.613\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63f19612b85f4cc4ac2630478fda6959",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:52:40 megatron_gpt_prompt_learning_model:440] val_loss: 1.59896981716156\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 1500: 'val_loss' reached 1.59897 (best 1.59897), saving model to '/net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/megatron_gpt_prompt_tune--val_loss=1.599-step=1500.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:52:40 nemo_model_checkpoint:168] New best .nemo model saved to: /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/p_tuning.nemo\n",
      "[NeMo I 2024-03-06 10:52:40 nlp_overrides:231] Removing checkpoint: /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/megatron_gpt_prompt_tune--val_loss=1.613-step=750-last.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.014 >= min_delta = 0.001. New best score: 1.599\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "946e3e986a68472db2a1f6e8009d504e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:54:25 megatron_gpt_prompt_learning_model:440] val_loss: 1.5840692520141602\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 2250: 'val_loss' reached 1.58407 (best 1.58407), saving model to '/net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/megatron_gpt_prompt_tune--val_loss=1.584-step=2250.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:54:25 nlp_overrides:231] Removing checkpoint: /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/megatron_gpt_prompt_tune--val_loss=1.613-step=750.ckpt\n",
      "[NeMo I 2024-03-06 10:54:25 nemo_model_checkpoint:168] New best .nemo model saved to: /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/p_tuning.nemo\n",
      "[NeMo I 2024-03-06 10:54:25 nlp_overrides:231] Removing checkpoint: /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/megatron_gpt_prompt_tune--val_loss=1.599-step=1500-last.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.015 >= min_delta = 0.001. New best score: 1.584\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f8fe77adcf2484596f3b030dd9fc0fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:56:09 megatron_gpt_prompt_learning_model:440] val_loss: 1.5770988464355469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 3000: 'val_loss' reached 1.57710 (best 1.57710), saving model to '/net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/megatron_gpt_prompt_tune--val_loss=1.577-step=3000.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:56:09 nlp_overrides:231] Removing checkpoint: /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/megatron_gpt_prompt_tune--val_loss=1.599-step=1500.ckpt\n",
      "[NeMo I 2024-03-06 10:56:09 nemo_model_checkpoint:168] New best .nemo model saved to: /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/p_tuning.nemo\n",
      "[NeMo I 2024-03-06 10:56:10 nlp_overrides:231] Removing checkpoint: /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/megatron_gpt_prompt_tune--val_loss=1.584-step=2250-last.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Metric val_loss improved by 0.007 >= min_delta = 0.001. New best score: 1.577\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e0fee367c947018a09ef8ccfef629a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:57:54 megatron_gpt_prompt_learning_model:440] val_loss: 1.57781183719635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 3750: 'val_loss' reached 1.57781 (best 1.57710), saving model to '/net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/megatron_gpt_prompt_tune--val_loss=1.578-step=3750.ckpt' as top 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:57:54 nemo_model_checkpoint:168] New best .nemo model saved to: /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/p_tuning.nemo\n",
      "[NeMo I 2024-03-06 10:57:54 nlp_overrides:231] Removing checkpoint: /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/megatron_gpt_prompt_tune--val_loss=1.584-step=2250.ckpt\n",
      "[NeMo I 2024-03-06 10:57:54 nemo_model_checkpoint:168] New best .nemo model saved to: /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/p_tuning.nemo\n",
      "[NeMo I 2024-03-06 10:57:54 nlp_overrides:231] Removing checkpoint: /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/megatron_gpt_prompt_tune--val_loss=1.577-step=3000-last.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 10:57:54 nemo_model_checkpoint:168] New best .nemo model saved to: /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/p_tuning.nemo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Restoring states from the checkpoint path at /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/megatron_gpt_prompt_tune--val_loss=1.577-step=3000.ckpt\n",
      "Restored all states from the checkpoint file at /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/megatron_gpt_prompt_tune--val_loss=1.577-step=3000.ckpt\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"MASTER_PORT\"] = \"51234\"\n",
    "\n",
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea50e43",
   "metadata": {},
   "source": [
    "## Inference After P-Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3cc37c",
   "metadata": {},
   "source": [
    "- Restore the Megatron-GPT Prompt Learning Model from the specified checkpoint path by `trainer.fit(model)` output above `eg:'../../jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-08-17_02-38-32/checkpoints/p_tuning.nemo'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d59ed47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 11:00:30 megatron_init:234] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2024-03-06 11:00:30 megatron_init:237] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 11:00:30 megatron_init:238] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2024-03-06 11:00:30 megatron_init:246] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2024-03-06 11:00:30 megatron_init:247] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 11:00:30 megatron_init:257] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2024-03-06 11:00:30 megatron_init:261] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 11:00:30 megatron_init:262] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2024-03-06 11:00:30 megatron_init:276] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2024-03-06 11:00:30 megatron_init:288] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2024-03-06 11:00:30 megatron_init:294] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 11:00:30 megatron_init:295] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2024-03-06 11:00:30 megatron_init:296] All embedding group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 11:00:30 megatron_init:297] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2024-03-06 11:01:11 megatron_init:234] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2024-03-06 11:01:11 megatron_init:237] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 11:01:11 megatron_init:238] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2024-03-06 11:01:11 megatron_init:246] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2024-03-06 11:01:11 megatron_init:247] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 11:01:11 megatron_init:257] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2024-03-06 11:01:11 megatron_init:261] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 11:01:11 megatron_init:262] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2024-03-06 11:01:11 megatron_init:276] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2024-03-06 11:01:11 megatron_init:288] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2024-03-06 11:01:11 megatron_init:294] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 11:01:11 megatron_init:295] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2024-03-06 11:01:11 megatron_init:296] All embedding group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 11:01:11 megatron_init:297] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2024-03-06 11:01:11 tokenizer_utils:204] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: None, and merges file: None\n",
      "[NeMo I 2024-03-06 11:01:11 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /net/people/tutorial/tutorial057/.cache/torch/megatron/megatron-gpt-345m_vocab, merges_files: /net/people/tutorial/tutorial057/.cache/torch/megatron/megatron-gpt-345m_merges, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 11:01:11 megatron_base_model:264] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.\n",
      "[NeMo I 2024-03-06 11:01:11 build_model:143]  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 812380160\n",
      "[NeMo I 2024-03-06 11:01:14 nlp_overrides:401] Model MegatronGPTModel was successfully restored from /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/source_code/nemo_gpt1.3B_fp16.nemo.\n",
      "[NeMo I 2024-03-06 11:01:14 auto_tokenizer:172] 15 special tokens added, resize your model accordingly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 11:01:54 megatron_init:234] Rank 0 has data parallel group: [0]\n",
      "[NeMo I 2024-03-06 11:01:54 megatron_init:237] All data parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 11:01:54 megatron_init:238] Ranks 0 has data parallel rank: 0\n",
      "[NeMo I 2024-03-06 11:01:54 megatron_init:246] Rank 0 has model parallel group: [0]\n",
      "[NeMo I 2024-03-06 11:01:54 megatron_init:247] All model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 11:01:54 megatron_init:257] Rank 0 has tensor model parallel group: [0]\n",
      "[NeMo I 2024-03-06 11:01:54 megatron_init:261] All tensor model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 11:01:54 megatron_init:262] Rank 0 has tensor model parallel rank: 0\n",
      "[NeMo I 2024-03-06 11:01:54 megatron_init:276] Rank 0 has pipeline model parallel group: [0]\n",
      "[NeMo I 2024-03-06 11:01:54 megatron_init:288] Rank 0 has embedding group: [0]\n",
      "[NeMo I 2024-03-06 11:01:54 megatron_init:294] All pipeline model parallel group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 11:01:54 megatron_init:295] Rank 0 has pipeline model parallel rank 0\n",
      "[NeMo I 2024-03-06 11:01:54 megatron_init:296] All embedding group ranks: [[0]]\n",
      "[NeMo I 2024-03-06 11:01:54 megatron_init:297] Rank 0 has embedding rank: 0\n",
      "[NeMo I 2024-03-06 11:01:54 tokenizer_utils:204] Getting Megatron tokenizer for pretrained model name: megatron-gpt-345m, custom vocab file: None, and merges file: None\n",
      "[NeMo I 2024-03-06 11:01:54 tokenizer_utils:130] Getting HuggingFace AutoTokenizer with pretrained_model_name: gpt2, vocab_file: /net/people/tutorial/tutorial057/.cache/torch/megatron/megatron-gpt-345m_vocab, merges_files: /net/people/tutorial/tutorial057/.cache/torch/megatron/megatron-gpt-345m_merges, special_tokens_dict: {}, and use_fast: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using sep_token, but it is not set yet.\n",
      "Using cls_token, but it is not set yet.\n",
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 11:01:54 megatron_base_model:264] Padded vocab_size: 50304, original vocab_size: 50257, dummy tokens: 47.\n",
      "[NeMo I 2024-03-06 11:01:54 build_model:143]  > number of parameters on (tensor, pipeline) model parallel rank (0, 0): 812380160\n",
      "[NeMo I 2024-03-06 11:01:56 nlp_overrides:401] Model MegatronGPTModel was successfully restored from /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/source_code/nemo_gpt1.3B_fp16.nemo.\n",
      "[NeMo I 2024-03-06 11:01:56 auto_tokenizer:172] 15 special tokens added, resize your model accordingly.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "Using mask_token, but it is not set yet.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 11:01:56 save_restore_connector:249] Model MegatronGPTPromptLearningModel was successfully restored from /net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/p_tuning.nemo.\n"
     ]
    }
   ],
   "source": [
    "# modify the restore_path to the path specified in the trainer.fit(model) output\n",
    "import nemo.collections.nlp as nemo_nlp\n",
    "\n",
    "mymodel = nemo_nlp.models.language_modeling.megatron_gpt_prompt_learning_model.MegatronGPTPromptLearningModel.restore_from(restore_path='/net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/p_tuning.nemo',trainer=trainer)\n",
    "# You can perform inference using this restored model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3432fcac",
   "metadata": {},
   "source": [
    "### Run the inference using the test examples below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a24bc4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = [\n",
    "    {'taskname': 'cuad',\n",
    "  'context': 'Exhibit 10.41\\n\\nSPONSORSHIP AGREEMENT\\n\\nThis Sponsorship Agreement (the \"Agreement\") is entered into effective January 1, 2010 by and between Stallings Capital Group  Consultants, Ltd., a Texas limited partnership dba Bob Stallings Racing (\"Racing\"), and GAINSCO, INC., a Texas corporation (the \"Sponsor\").\\n\\nRacing organized and operated a racing team engaging in Daytona Prototype Series auto racing (the \"Racing Team\") in professional races in  2005 through 2008, and the Sponsor was the primary sponsor of the Racing Team pursuant to Sponsorship Agreements dated February 7, 2005,  February 1, 2006, January 1, 2007, January 1, 2008 and January 1, 2009. Racing has invited the Sponsor to continue to act as the primary sponsor of  the Racing Team for 2010, and the Sponsor desires to act in that capacity. In consideration of the sponsorship fee provided for herein, the parties  desire to enter into this Agreement to govern the terms of such sponsorship in 2010.\\n\\nNow, therefore, Racing and the Sponsor hereby agree as follows:\\n\\n1. Term. Subject to the provisions of Section 14 hereof, the term of this Agreement and the sponsorship described herein shall commence on  January 1, 2010 and extend through December 31, 2010.\\n\\n2. Advertising and Other Benefits. Subject to payment by the Sponsor of the sponsorship fee provided for herein, during the term of this  Agreement Racing shall cause the Racing Team to provide for the Sponsor\\'s benefit all of the benefits customarily associated with the  sponsorship of a Daytona Prototype Series racing team and consistent with the benefits provided to the Sponsor in 2005 - 2009 (individually, a  \"Benefit,\" and collectively, the \"Benefits\"), including but not limited to the following:   (i) displaying prominent identification of the Sponsor\\'s name and/or logo in signage on the race car and racing suits and, where  appropriate, on other team equipment (subject to approval by the Sponsor);   (ii) making available for the use of the Sponsor (x) the personalities associated with the Racing Team, including without limitation  the name, voice, picture, portrait, likeness, persona and/or signature of each driver for endorsements, commercial advertising and  promotions in any and all media throughout the world during the term of this Agreement, (y) the Racing Team\\'s home base facilities in  Texas, and (z) those facilities designated or assigned for the use of the Racing Team at each race and race location at which the Racing  Team actually participates in the race, all for appropriate public relations and other promotional and marketing purposes. Racing agrees  that it will actively participate in the Rolex 24 at Daytona in January, 2010. As it concerns (y) and (z) above, access shall be subject to  appropriate security and safety restrictions designated by the applicable racing location and the Racing Team;\\n\\n\\n\\n\\n\\n(iii) making available for the use of the Sponsor a non-racing look-alike (a \"Show Car\") of the GAINSCO 99 race car (the \"Car\")  used by the Racing Team. Subject to the Sponsor\\'s first right to use the Show Car, it will also be made available to Racing when such  use does not interfere with the Sponsor\\'s use of the Show Car;   (iv) allowing the Sponsor the use of the likeness of the Car, including all paint and graphics, for promotion and advertising of or  by the Sponsor, and Racing shall be responsible for all necessary consents and permissions from any other sponsors to be sure the  Sponsor can use the likeness of the Car as specified herein;   (v) prohibiting the endorsement by Racing and any members of Racing, including the drivers, of any entities, products or  services which are in direct competition or otherwise inconsistent with the Sponsor or it products or services, unless such  endorsement activity is approved in writing by Racing and the Sponsor; and   (vi) allowing the Sponsor to use the conference room and other areas of the racing shop and garage for meetings and similar  events, provided that the Sponsor gives prior notice of the need for such use, and such use does not interfere with operations of the  racing shop and garage and is otherwise consistent with reasonable requirements imposed by Racing to assure orderly operations and  provide for adequate safety measures at all times.\\n\\n3. Sponsorship Fee. The Sponsor shall pay to Racing a sponsorship fee in the amount of $750,000.00 for the term of this Agreement, payable  in an initial installment payable on or before February 1, 2010 in the amount of $350,000.00 and ten installments of $40,000.00 on or before the first  day of each month commencing March 1, 2010 and ending with the installment due on December 1, 2010 (unless this Agreement is sooner  terminated pursuant to Section 14 hereof, in which case Sponsor shall have no obligation to make any payments after the date of termination).\\n\\n4. Compliance with Applicable Rules and Regulations. Provision of the Benefits pursuant to this Agreement is subject to rules and  requirements of each organization and venue hosting a racing event in which the Racing Team competes during the term hereof, and the Sponsor  agrees to submit to Racing all advertising and other promotional material relating to each such event in sufficient time to enable Racing to assure  compliance with such rules and requirements. If as a result of such rules and requirements Racing is unable to provide a Benefit in the form  requested by the Sponsor, Racing shall be permitted to provide a substitute promotion or advertisement in compliance with such requirements.      2\\n\\n\\n\\n\\n\\n5. Sponsor\\'s Maximum Obligation; Indemnification. Racing represents to the Sponsor that the Sponsor\\'s aggregate obligation hereunder  will not exceed the amount of the sponsorship fee set forth in Section 3 hereof (or such lesser amount as is payable by the Sponsor in the event  that this Agreement is terminated pursuant to Section 14 hereof), plus, if applicable, collection costs that may be reasonably incurred by Racing in  a legal proceeding to collect all or any part thereof (the \"Maximum Obligation\"). Racing agrees to indemnify the Sponsor and its officers, directors,  agents and employees and to hold them harmless from any loss, claim, cost, damage or liability in excess of the Maximum Obligation which (i) the  Sponsor shall incur as a result of this Agreement, or (ii) arises from any failure by Racing to perform any of its obligations hereunder.\\n\\n6. Retention of Rights. The only rights granted to the Sponsor hereunder are the right to receive the Benefits, and Racing hereby retains all  other rights with respect to the Racing Team, including but not limited to logos, symbols, names and other marks and intellectual property of the  Racing Team, and any proceeds derived by the Racing Team. The Sponsor hereby retains and does not grant any rights to Racing to use any of its  logos, symbols, names or other marks or intellectual property, except for use as described in Section 2 hereof. In the event that this Agreement is  terminated or if the sponsorship terminates at the end of the term provided for herein, each of the parties shall retain the rights to use its logos,  symbols, names or other marks or intellectual property including, in the case of the Sponsor, the right to use the names and marks \"GAINSCO 99\",  \"the GAINSCO 99 Car\", or similar phrases or derivations thereof.\\n\\n7. Relationship to Other Sponsors. The Sponsor acknowledges that Racing has arranged and may arrange in the future for other sponsors  for the Racing Team. Racing agrees that, during the term of this Agreement, (i) Sponsor shall have the right to approve or disapprove any  additional sponsor identified by Racing, and (ii) unless another proposed sponsor has agreed to pay a sponsorship fee that exceeds the amount  paid by Sponsor, no other sponsor shall receive any benefit of greater value (including either an equivalent or a more prominent use of another  sponsor\\'s name, logo or other identifying information) than the Benefits provided to the Sponsor hereunder.\\n\\n8. Insurance.   (a) Racing shall obtain and maintain, at Racing\\'s expense, comprehensive automobile liability insurance covering all owned, non-owned and  hired vehicles used by Racing in the Business with limits of not less than $5,000,000 per occurrence combined single limit for personal injury and  property damage, including all statutory coverage for all states of operation. Racing shall also provide comprehensive (fire and theft) and collision  insurance on each vehicle used in the Business. Racing shall provide the Sponsor a certificate of insurance evidencing \"Gainsco Inc. and all  related entities\" as additional insureds, stating that such insurance is primary in coverage to any other insurance which may be available the  Sponsor, and providing at least thirty (30) days\\' prior written notice to the Sponsor of cancellation, modification or material change to the policy.\\n\\n(b) Racing shall obtain and maintain pursuant to the terms of this Agreement, at its sole expense, the following types of insurance coverage,  with minimum limits as set forth below:\\n\\n(i) Commercial General Liability covering liability arising from premises, operations, independent contractors, personal and advertising injury  and contractual liability—$5,000,000 each occurrence.      3\\n\\n\\n\\n\\n\\n(ii) Racing Owners\\' Sponsors (Spectators) Legal Liability including Participant Legal Liability—$5,000,000 each occurrence.\\n\\n(iii) Business Automobile Liability covering all owned, hired and non-owned vehicles—$5,000,000 each occurrence, including statutory  coverages for all states of operations.\\n\\n(iv) Workers Compensation—statutory limits for all states of operation.\\n\\n(v) Employers Liability—$5,000,000 each employee for bodily injury by accident and $500,000 each employee for bodily injury by disease.\\n\\nAll policies of insurance procured by Racing herein shall be written as primary policies, not contributing with or in excess of coverage that the  Sponsor may carry. If Racing\\'s liability policies do not contain the standard separation of insureds provision, or a substantially similar clause, they  shall be endorsed to provide cross-liability coverage.\\n\\n(c) Racing shall provide the Sponsor with a certificate of insurance evidence compliance with the insurance requirements set forth above.  Certificates shall provide that \"Gainsco Inc. and all related entities\" shall be named as additional insureds on all liability policies, stating that such  insurance is primary in coverage to any other insurance which may be available to the Sponsor, and providing at least thirty (30) days\\' prior  written notice to the Sponsor of termination, cancellation, modification or material change to the policy.\\n\\n(d) Such certificates shall be in a form acceptable to, and underwritten by insurance company(ies) reasonably satisfactory to the Sponsor. By  requiring insurance herein, the Sponsor does not represent that coverage limits will necessarily be adequate to protect Racing. The purchase of  appropriate insurance coverage by Racing or the furnishing of certificates of insurance shall not release Racing from its obligations and liabilities  under this Agreement.\\n\\n9. Conduct. Racing and all Racing members, including but not limited to all drivers, agree to use best efforts to conduct themselves in such a  manner so as not to reflect unfavorably upon the Sponsor or its products. The Sponsor shall have the right to terminate this Agreement on written  notice to Racing if any driver, the general manager or any other member of Racing (i) fails to conduct himself/herself in accordance with generally  accepted standards of morality, (ii) engages in any activity which reflects adversely on the image, reputation or goodwill of the Sponsor or (iii)  disparages the products or services of the Sponsor; provided, however, the Sponsor shall not have the right to terminate this Agreement if Racing,  within fifteen (15) days after receipt of written notice by the Sponsor terminates the employment of, or otherwise dismisses from the racing team,  the driver(s), general manager(s) or other member(s) of Racing engaging in the offensive conduct. Upon termination, the Sponsor shall be entitled  to a pro rata refund of monies paid for services not yet performed by Racing based upon the number of races for the applicable racing season. The  Sponsor\\'s decision with respect to all matters arising under this Section shall be conclusive.      4\\n\\n\\n\\n\\n\\n10. Remedies. If either party breaches any provision of this Agreement, the other party shall be entitled to seek monetary damages and, if  appropriate, equitable relief to require the performance of the obligations hereunder.\\n\\n11. Assignment. Neither party shall assign any of its rights or obligations hereunder without the prior written consent of the other party.\\n\\n12. Entire Agreement; Amendment and Waiver; Confidentiality. This Agreement constitutes the entire agreement between Racing and the  Sponsor with respect to the subject matter hereof and supercedes all prior agreements and understandings. Any amendment of this Agreement  must be by a written instrument signed by both parties, and any waiver of any provision hereof must be in writing, signed by the party agreeing to  such waiver. Each of the parties hereto agrees to hold in confidence the terms hereof and, unless otherwise required by law, neither party shall  release, disclose or publish any of the terms hereof without the prior written consent of the other party.\\n\\n13. Notices. All notices and communications to be made with respect to this Agreement shall be in writing and shall be effective only when  delivered by (i) hand, (ii) prepaid certified United States mail, return receipt requested, or (iii) overnight delivery service providing proof of delivery,  addressed as follows:\\n\\nIf to Racing:   Stallings Capital Group Consultants, Ltd., dba Bob Stallings Racing   Attention: Robert W. Stallings, President   4 Windsor Ridge   Frisco, Texas 75034\\n\\nif to the Sponsor:   GAINSCO, Inc.   Attention: Glenn W. Anderson, President   3333 Lee Parkway, Suite 1200   Dallas, Texas 75219\\n\\nEither party may change the name or address for notice by providing a written notice of such change in accordance with this Section of the  Agreement.\\n\\n14. Termination by the Sponsor. Notwithstanding the provisions of Section 1 hereof, the Sponsor shall have the right at any time prior to  December 31, 2010 to terminate this Agreement by giving written notice of such termination to Racing. In the event of such a termination, (i) the  Sponsor shall have no further obligation to make payments toward the sponsorship fee contemplated in Section 3 hereof, (ii) Racing shall have no  further obligation to provide any Benefits hereunder, and (iii) the remaining provisions of this Agreement shall remain in full force and effect.\\n\\n15. Miscellaneous. (a) This Agreement may be executed in two counterparts, each of which shall be deemed to be an original, but both of  which shall constitute a single agreement.      5\\n\\n\\n\\n\\n\\n(b) The headings and sections of this Agreement are for convenience only and shall not affect the interpretation of any provision hereof.\\n\\n(c) This Agreement shall be governed and construed in accordance with the internal laws of the State of Texas, without giving effect to  principles of conflict of laws.\\n\\nThis Agreement is executed as of the date first above written.\\n\\n   6\\n\\nSTALLINGS CAPITAL GROUP CONSULTANTS, LTD., DBA BOB  STALLINGS RACING     GAINSCO, INC.\\n\\nBy:  /s/ Robert W. Stallings     By:  /s/ Glenn W. Anderson    Robert W. Stallings, President       Glenn W. Anderson, President',\n",
    "  'question': 'Highlight the parts (if any) of this contract related to \"Document Name\" that should be reviewed by a lawyer. Details: The name of the contract'},\n",
    "    {'taskname': 'cuad',\n",
    "  'context': 'Exhibit 10.41\\n\\nSPONSORSHIP AGREEMENT\\n\\nThis Sponsorship Agreement (the \"Agreement\") is entered into effective January 1, 2010 by and between Stallings Capital Group  Consultants, Ltd., a Texas limited partnership dba Bob Stallings Racing (\"Racing\"), and GAINSCO, INC., a Texas corporation (the \"Sponsor\").\\n\\nRacing organized and operated a racing team engaging in Daytona Prototype Series auto racing (the \"Racing Team\") in professional races in  2005 through 2008, and the Sponsor was the primary sponsor of the Racing Team pursuant to Sponsorship Agreements dated February 7, 2005,  February 1, 2006, January 1, 2007, January 1, 2008 and January 1, 2009. Racing has invited the Sponsor to continue to act as the primary sponsor of  the Racing Team for 2010, and the Sponsor desires to act in that capacity. In consideration of the sponsorship fee provided for herein, the parties  desire to enter into this Agreement to govern the terms of such sponsorship in 2010.\\n\\nNow, therefore, Racing and the Sponsor hereby agree as follows:\\n\\n1. Term. Subject to the provisions of Section 14 hereof, the term of this Agreement and the sponsorship described herein shall commence on  January 1, 2010 and extend through December 31, 2010.\\n\\n2. Advertising and Other Benefits. Subject to payment by the Sponsor of the sponsorship fee provided for herein, during the term of this  Agreement Racing shall cause the Racing Team to provide for the Sponsor\\'s benefit all of the benefits customarily associated with the  sponsorship of a Daytona Prototype Series racing team and consistent with the benefits provided to the Sponsor in 2005 - 2009 (individually, a  \"Benefit,\" and collectively, the \"Benefits\"), including but not limited to the following:   (i) displaying prominent identification of the Sponsor\\'s name and/or logo in signage on the race car and racing suits and, where  appropriate, on other team equipment (subject to approval by the Sponsor);   (ii) making available for the use of the Sponsor (x) the personalities associated with the Racing Team, including without limitation  the name, voice, picture, portrait, likeness, persona and/or signature of each driver for endorsements, commercial advertising and  promotions in any and all media throughout the world during the term of this Agreement, (y) the Racing Team\\'s home base facilities in  Texas, and (z) those facilities designated or assigned for the use of the Racing Team at each race and race location at which the Racing  Team actually participates in the race, all for appropriate public relations and other promotional and marketing purposes. Racing agrees  that it will actively participate in the Rolex 24 at Daytona in January, 2010. As it concerns (y) and (z) above, access shall be subject to  appropriate security and safety restrictions designated by the applicable racing location and the Racing Team;\\n\\n\\n\\n\\n\\n(iii) making available for the use of the Sponsor a non-racing look-alike (a \"Show Car\") of the GAINSCO 99 race car (the \"Car\")  used by the Racing Team. Subject to the Sponsor\\'s first right to use the Show Car, it will also be made available to Racing when such  use does not interfere with the Sponsor\\'s use of the Show Car;   (iv) allowing the Sponsor the use of the likeness of the Car, including all paint and graphics, for promotion and advertising of or  by the Sponsor, and Racing shall be responsible for all necessary consents and permissions from any other sponsors to be sure the  Sponsor can use the likeness of the Car as specified herein;   (v) prohibiting the endorsement by Racing and any members of Racing, including the drivers, of any entities, products or  services which are in direct competition or otherwise inconsistent with the Sponsor or it products or services, unless such  endorsement activity is approved in writing by Racing and the Sponsor; and   (vi) allowing the Sponsor to use the conference room and other areas of the racing shop and garage for meetings and similar  events, provided that the Sponsor gives prior notice of the need for such use, and such use does not interfere with operations of the  racing shop and garage and is otherwise consistent with reasonable requirements imposed by Racing to assure orderly operations and  provide for adequate safety measures at all times.\\n\\n3. Sponsorship Fee. The Sponsor shall pay to Racing a sponsorship fee in the amount of $750,000.00 for the term of this Agreement, payable  in an initial installment payable on or before February 1, 2010 in the amount of $350,000.00 and ten installments of $40,000.00 on or before the first  day of each month commencing March 1, 2010 and ending with the installment due on December 1, 2010 (unless this Agreement is sooner  terminated pursuant to Section 14 hereof, in which case Sponsor shall have no obligation to make any payments after the date of termination).\\n\\n4. Compliance with Applicable Rules and Regulations. Provision of the Benefits pursuant to this Agreement is subject to rules and  requirements of each organization and venue hosting a racing event in which the Racing Team competes during the term hereof, and the Sponsor  agrees to submit to Racing all advertising and other promotional material relating to each such event in sufficient time to enable Racing to assure  compliance with such rules and requirements. If as a result of such rules and requirements Racing is unable to provide a Benefit in the form  requested by the Sponsor, Racing shall be permitted to provide a substitute promotion or advertisement in compliance with such requirements.      2\\n\\n\\n\\n\\n\\n5. Sponsor\\'s Maximum Obligation; Indemnification. Racing represents to the Sponsor that the Sponsor\\'s aggregate obligation hereunder  will not exceed the amount of the sponsorship fee set forth in Section 3 hereof (or such lesser amount as is payable by the Sponsor in the event  that this Agreement is terminated pursuant to Section 14 hereof), plus, if applicable, collection costs that may be reasonably incurred by Racing in  a legal proceeding to collect all or any part thereof (the \"Maximum Obligation\"). Racing agrees to indemnify the Sponsor and its officers, directors,  agents and employees and to hold them harmless from any loss, claim, cost, damage or liability in excess of the Maximum Obligation which (i) the  Sponsor shall incur as a result of this Agreement, or (ii) arises from any failure by Racing to perform any of its obligations hereunder.\\n\\n6. Retention of Rights. The only rights granted to the Sponsor hereunder are the right to receive the Benefits, and Racing hereby retains all  other rights with respect to the Racing Team, including but not limited to logos, symbols, names and other marks and intellectual property of the  Racing Team, and any proceeds derived by the Racing Team. The Sponsor hereby retains and does not grant any rights to Racing to use any of its  logos, symbols, names or other marks or intellectual property, except for use as described in Section 2 hereof. In the event that this Agreement is  terminated or if the sponsorship terminates at the end of the term provided for herein, each of the parties shall retain the rights to use its logos,  symbols, names or other marks or intellectual property including, in the case of the Sponsor, the right to use the names and marks \"GAINSCO 99\",  \"the GAINSCO 99 Car\", or similar phrases or derivations thereof.\\n\\n7. Relationship to Other Sponsors. The Sponsor acknowledges that Racing has arranged and may arrange in the future for other sponsors  for the Racing Team. Racing agrees that, during the term of this Agreement, (i) Sponsor shall have the right to approve or disapprove any  additional sponsor identified by Racing, and (ii) unless another proposed sponsor has agreed to pay a sponsorship fee that exceeds the amount  paid by Sponsor, no other sponsor shall receive any benefit of greater value (including either an equivalent or a more prominent use of another  sponsor\\'s name, logo or other identifying information) than the Benefits provided to the Sponsor hereunder.\\n\\n8. Insurance.   (a) Racing shall obtain and maintain, at Racing\\'s expense, comprehensive automobile liability insurance covering all owned, non-owned and  hired vehicles used by Racing in the Business with limits of not less than $5,000,000 per occurrence combined single limit for personal injury and  property damage, including all statutory coverage for all states of operation. Racing shall also provide comprehensive (fire and theft) and collision  insurance on each vehicle used in the Business. Racing shall provide the Sponsor a certificate of insurance evidencing \"Gainsco Inc. and all  related entities\" as additional insureds, stating that such insurance is primary in coverage to any other insurance which may be available the  Sponsor, and providing at least thirty (30) days\\' prior written notice to the Sponsor of cancellation, modification or material change to the policy.\\n\\n(b) Racing shall obtain and maintain pursuant to the terms of this Agreement, at its sole expense, the following types of insurance coverage,  with minimum limits as set forth below:\\n\\n(i) Commercial General Liability covering liability arising from premises, operations, independent contractors, personal and advertising injury  and contractual liability—$5,000,000 each occurrence.      3\\n\\n\\n\\n\\n\\n(ii) Racing Owners\\' Sponsors (Spectators) Legal Liability including Participant Legal Liability—$5,000,000 each occurrence.\\n\\n(iii) Business Automobile Liability covering all owned, hired and non-owned vehicles—$5,000,000 each occurrence, including statutory  coverages for all states of operations.\\n\\n(iv) Workers Compensation—statutory limits for all states of operation.\\n\\n(v) Employers Liability—$5,000,000 each employee for bodily injury by accident and $500,000 each employee for bodily injury by disease.\\n\\nAll policies of insurance procured by Racing herein shall be written as primary policies, not contributing with or in excess of coverage that the  Sponsor may carry. If Racing\\'s liability policies do not contain the standard separation of insureds provision, or a substantially similar clause, they  shall be endorsed to provide cross-liability coverage.\\n\\n(c) Racing shall provide the Sponsor with a certificate of insurance evidence compliance with the insurance requirements set forth above.  Certificates shall provide that \"Gainsco Inc. and all related entities\" shall be named as additional insureds on all liability policies, stating that such  insurance is primary in coverage to any other insurance which may be available to the Sponsor, and providing at least thirty (30) days\\' prior  written notice to the Sponsor of termination, cancellation, modification or material change to the policy.\\n\\n(d) Such certificates shall be in a form acceptable to, and underwritten by insurance company(ies) reasonably satisfactory to the Sponsor. By  requiring insurance herein, the Sponsor does not represent that coverage limits will necessarily be adequate to protect Racing. The purchase of  appropriate insurance coverage by Racing or the furnishing of certificates of insurance shall not release Racing from its obligations and liabilities  under this Agreement.\\n\\n9. Conduct. Racing and all Racing members, including but not limited to all drivers, agree to use best efforts to conduct themselves in such a  manner so as not to reflect unfavorably upon the Sponsor or its products. The Sponsor shall have the right to terminate this Agreement on written  notice to Racing if any driver, the general manager or any other member of Racing (i) fails to conduct himself/herself in accordance with generally  accepted standards of morality, (ii) engages in any activity which reflects adversely on the image, reputation or goodwill of the Sponsor or (iii)  disparages the products or services of the Sponsor; provided, however, the Sponsor shall not have the right to terminate this Agreement if Racing,  within fifteen (15) days after receipt of written notice by the Sponsor terminates the employment of, or otherwise dismisses from the racing team,  the driver(s), general manager(s) or other member(s) of Racing engaging in the offensive conduct. Upon termination, the Sponsor shall be entitled  to a pro rata refund of monies paid for services not yet performed by Racing based upon the number of races for the applicable racing season. The  Sponsor\\'s decision with respect to all matters arising under this Section shall be conclusive.      4\\n\\n\\n\\n\\n\\n10. Remedies. If either party breaches any provision of this Agreement, the other party shall be entitled to seek monetary damages and, if  appropriate, equitable relief to require the performance of the obligations hereunder.\\n\\n11. Assignment. Neither party shall assign any of its rights or obligations hereunder without the prior written consent of the other party.\\n\\n12. Entire Agreement; Amendment and Waiver; Confidentiality. This Agreement constitutes the entire agreement between Racing and the  Sponsor with respect to the subject matter hereof and supercedes all prior agreements and understandings. Any amendment of this Agreement  must be by a written instrument signed by both parties, and any waiver of any provision hereof must be in writing, signed by the party agreeing to  such waiver. Each of the parties hereto agrees to hold in confidence the terms hereof and, unless otherwise required by law, neither party shall  release, disclose or publish any of the terms hereof without the prior written consent of the other party.\\n\\n13. Notices. All notices and communications to be made with respect to this Agreement shall be in writing and shall be effective only when  delivered by (i) hand, (ii) prepaid certified United States mail, return receipt requested, or (iii) overnight delivery service providing proof of delivery,  addressed as follows:\\n\\nIf to Racing:   Stallings Capital Group Consultants, Ltd., dba Bob Stallings Racing   Attention: Robert W. Stallings, President   4 Windsor Ridge   Frisco, Texas 75034\\n\\nif to the Sponsor:   GAINSCO, Inc.   Attention: Glenn W. Anderson, President   3333 Lee Parkway, Suite 1200   Dallas, Texas 75219\\n\\nEither party may change the name or address for notice by providing a written notice of such change in accordance with this Section of the  Agreement.\\n\\n14. Termination by the Sponsor. Notwithstanding the provisions of Section 1 hereof, the Sponsor shall have the right at any time prior to  December 31, 2010 to terminate this Agreement by giving written notice of such termination to Racing. In the event of such a termination, (i) the  Sponsor shall have no further obligation to make payments toward the sponsorship fee contemplated in Section 3 hereof, (ii) Racing shall have no  further obligation to provide any Benefits hereunder, and (iii) the remaining provisions of this Agreement shall remain in full force and effect.\\n\\n15. Miscellaneous. (a) This Agreement may be executed in two counterparts, each of which shall be deemed to be an original, but both of  which shall constitute a single agreement.      5\\n\\n\\n\\n\\n\\n(b) The headings and sections of this Agreement are for convenience only and shall not affect the interpretation of any provision hereof.\\n\\n(c) This Agreement shall be governed and construed in accordance with the internal laws of the State of Texas, without giving effect to  principles of conflict of laws.\\n\\nThis Agreement is executed as of the date first above written.\\n\\n   6\\n\\nSTALLINGS CAPITAL GROUP CONSULTANTS, LTD., DBA BOB  STALLINGS RACING     GAINSCO, INC.\\n\\nBy:  /s/ Robert W. Stallings     By:  /s/ Glenn W. Anderson    Robert W. Stallings, President       Glenn W. Anderson, President',\n",
    "  'question': 'Highlight the parts (if any) of this contract related to \"Agreement Date\" that should be reviewed by a lawyer. Details: The date of the contract'},\n",
    "    {'taskname': 'cuad',\n",
    "  'context': 'Exhibit 10.41\\n\\nSPONSORSHIP AGREEMENT\\n\\nThis Sponsorship Agreement (the \"Agreement\") is entered into effective January 1, 2010 by and between Stallings Capital Group  Consultants, Ltd., a Texas limited partnership dba Bob Stallings Racing (\"Racing\"), and GAINSCO, INC., a Texas corporation (the \"Sponsor\").\\n\\nRacing organized and operated a racing team engaging in Daytona Prototype Series auto racing (the \"Racing Team\") in professional races in  2005 through 2008, and the Sponsor was the primary sponsor of the Racing Team pursuant to Sponsorship Agreements dated February 7, 2005,  February 1, 2006, January 1, 2007, January 1, 2008 and January 1, 2009. Racing has invited the Sponsor to continue to act as the primary sponsor of  the Racing Team for 2010, and the Sponsor desires to act in that capacity. In consideration of the sponsorship fee provided for herein, the parties  desire to enter into this Agreement to govern the terms of such sponsorship in 2010.\\n\\nNow, therefore, Racing and the Sponsor hereby agree as follows:\\n\\n1. Term. Subject to the provisions of Section 14 hereof, the term of this Agreement and the sponsorship described herein shall commence on  January 1, 2010 and extend through December 31, 2010.\\n\\n2. Advertising and Other Benefits. Subject to payment by the Sponsor of the sponsorship fee provided for herein, during the term of this  Agreement Racing shall cause the Racing Team to provide for the Sponsor\\'s benefit all of the benefits customarily associated with the  sponsorship of a Daytona Prototype Series racing team and consistent with the benefits provided to the Sponsor in 2005 - 2009 (individually, a  \"Benefit,\" and collectively, the \"Benefits\"), including but not limited to the following:   (i) displaying prominent identification of the Sponsor\\'s name and/or logo in signage on the race car and racing suits and, where  appropriate, on other team equipment (subject to approval by the Sponsor);   (ii) making available for the use of the Sponsor (x) the personalities associated with the Racing Team, including without limitation  the name, voice, picture, portrait, likeness, persona and/or signature of each driver for endorsements, commercial advertising and  promotions in any and all media throughout the world during the term of this Agreement, (y) the Racing Team\\'s home base facilities in  Texas, and (z) those facilities designated or assigned for the use of the Racing Team at each race and race location at which the Racing  Team actually participates in the race, all for appropriate public relations and other promotional and marketing purposes. Racing agrees  that it will actively participate in the Rolex 24 at Daytona in January, 2010. As it concerns (y) and (z) above, access shall be subject to  appropriate security and safety restrictions designated by the applicable racing location and the Racing Team;\\n\\n\\n\\n\\n\\n(iii) making available for the use of the Sponsor a non-racing look-alike (a \"Show Car\") of the GAINSCO 99 race car (the \"Car\")  used by the Racing Team. Subject to the Sponsor\\'s first right to use the Show Car, it will also be made available to Racing when such  use does not interfere with the Sponsor\\'s use of the Show Car;   (iv) allowing the Sponsor the use of the likeness of the Car, including all paint and graphics, for promotion and advertising of or  by the Sponsor, and Racing shall be responsible for all necessary consents and permissions from any other sponsors to be sure the  Sponsor can use the likeness of the Car as specified herein;   (v) prohibiting the endorsement by Racing and any members of Racing, including the drivers, of any entities, products or  services which are in direct competition or otherwise inconsistent with the Sponsor or it products or services, unless such  endorsement activity is approved in writing by Racing and the Sponsor; and   (vi) allowing the Sponsor to use the conference room and other areas of the racing shop and garage for meetings and similar  events, provided that the Sponsor gives prior notice of the need for such use, and such use does not interfere with operations of the  racing shop and garage and is otherwise consistent with reasonable requirements imposed by Racing to assure orderly operations and  provide for adequate safety measures at all times.\\n\\n3. Sponsorship Fee. The Sponsor shall pay to Racing a sponsorship fee in the amount of $750,000.00 for the term of this Agreement, payable  in an initial installment payable on or before February 1, 2010 in the amount of $350,000.00 and ten installments of $40,000.00 on or before the first  day of each month commencing March 1, 2010 and ending with the installment due on December 1, 2010 (unless this Agreement is sooner  terminated pursuant to Section 14 hereof, in which case Sponsor shall have no obligation to make any payments after the date of termination).\\n\\n4. Compliance with Applicable Rules and Regulations. Provision of the Benefits pursuant to this Agreement is subject to rules and  requirements of each organization and venue hosting a racing event in which the Racing Team competes during the term hereof, and the Sponsor  agrees to submit to Racing all advertising and other promotional material relating to each such event in sufficient time to enable Racing to assure  compliance with such rules and requirements. If as a result of such rules and requirements Racing is unable to provide a Benefit in the form  requested by the Sponsor, Racing shall be permitted to provide a substitute promotion or advertisement in compliance with such requirements.      2\\n\\n\\n\\n\\n\\n5. Sponsor\\'s Maximum Obligation; Indemnification. Racing represents to the Sponsor that the Sponsor\\'s aggregate obligation hereunder  will not exceed the amount of the sponsorship fee set forth in Section 3 hereof (or such lesser amount as is payable by the Sponsor in the event  that this Agreement is terminated pursuant to Section 14 hereof), plus, if applicable, collection costs that may be reasonably incurred by Racing in  a legal proceeding to collect all or any part thereof (the \"Maximum Obligation\"). Racing agrees to indemnify the Sponsor and its officers, directors,  agents and employees and to hold them harmless from any loss, claim, cost, damage or liability in excess of the Maximum Obligation which (i) the  Sponsor shall incur as a result of this Agreement, or (ii) arises from any failure by Racing to perform any of its obligations hereunder.\\n\\n6. Retention of Rights. The only rights granted to the Sponsor hereunder are the right to receive the Benefits, and Racing hereby retains all  other rights with respect to the Racing Team, including but not limited to logos, symbols, names and other marks and intellectual property of the  Racing Team, and any proceeds derived by the Racing Team. The Sponsor hereby retains and does not grant any rights to Racing to use any of its  logos, symbols, names or other marks or intellectual property, except for use as described in Section 2 hereof. In the event that this Agreement is  terminated or if the sponsorship terminates at the end of the term provided for herein, each of the parties shall retain the rights to use its logos,  symbols, names or other marks or intellectual property including, in the case of the Sponsor, the right to use the names and marks \"GAINSCO 99\",  \"the GAINSCO 99 Car\", or similar phrases or derivations thereof.\\n\\n7. Relationship to Other Sponsors. The Sponsor acknowledges that Racing has arranged and may arrange in the future for other sponsors  for the Racing Team. Racing agrees that, during the term of this Agreement, (i) Sponsor shall have the right to approve or disapprove any  additional sponsor identified by Racing, and (ii) unless another proposed sponsor has agreed to pay a sponsorship fee that exceeds the amount  paid by Sponsor, no other sponsor shall receive any benefit of greater value (including either an equivalent or a more prominent use of another  sponsor\\'s name, logo or other identifying information) than the Benefits provided to the Sponsor hereunder.\\n\\n8. Insurance.   (a) Racing shall obtain and maintain, at Racing\\'s expense, comprehensive automobile liability insurance covering all owned, non-owned and  hired vehicles used by Racing in the Business with limits of not less than $5,000,000 per occurrence combined single limit for personal injury and  property damage, including all statutory coverage for all states of operation. Racing shall also provide comprehensive (fire and theft) and collision  insurance on each vehicle used in the Business. Racing shall provide the Sponsor a certificate of insurance evidencing \"Gainsco Inc. and all  related entities\" as additional insureds, stating that such insurance is primary in coverage to any other insurance which may be available the  Sponsor, and providing at least thirty (30) days\\' prior written notice to the Sponsor of cancellation, modification or material change to the policy.\\n\\n(b) Racing shall obtain and maintain pursuant to the terms of this Agreement, at its sole expense, the following types of insurance coverage,  with minimum limits as set forth below:\\n\\n(i) Commercial General Liability covering liability arising from premises, operations, independent contractors, personal and advertising injury  and contractual liability—$5,000,000 each occurrence.      3\\n\\n\\n\\n\\n\\n(ii) Racing Owners\\' Sponsors (Spectators) Legal Liability including Participant Legal Liability—$5,000,000 each occurrence.\\n\\n(iii) Business Automobile Liability covering all owned, hired and non-owned vehicles—$5,000,000 each occurrence, including statutory  coverages for all states of operations.\\n\\n(iv) Workers Compensation—statutory limits for all states of operation.\\n\\n(v) Employers Liability—$5,000,000 each employee for bodily injury by accident and $500,000 each employee for bodily injury by disease.\\n\\nAll policies of insurance procured by Racing herein shall be written as primary policies, not contributing with or in excess of coverage that the  Sponsor may carry. If Racing\\'s liability policies do not contain the standard separation of insureds provision, or a substantially similar clause, they  shall be endorsed to provide cross-liability coverage.\\n\\n(c) Racing shall provide the Sponsor with a certificate of insurance evidence compliance with the insurance requirements set forth above.  Certificates shall provide that \"Gainsco Inc. and all related entities\" shall be named as additional insureds on all liability policies, stating that such  insurance is primary in coverage to any other insurance which may be available to the Sponsor, and providing at least thirty (30) days\\' prior  written notice to the Sponsor of termination, cancellation, modification or material change to the policy.\\n\\n(d) Such certificates shall be in a form acceptable to, and underwritten by insurance company(ies) reasonably satisfactory to the Sponsor. By  requiring insurance herein, the Sponsor does not represent that coverage limits will necessarily be adequate to protect Racing. The purchase of  appropriate insurance coverage by Racing or the furnishing of certificates of insurance shall not release Racing from its obligations and liabilities  under this Agreement.\\n\\n9. Conduct. Racing and all Racing members, including but not limited to all drivers, agree to use best efforts to conduct themselves in such a  manner so as not to reflect unfavorably upon the Sponsor or its products. The Sponsor shall have the right to terminate this Agreement on written  notice to Racing if any driver, the general manager or any other member of Racing (i) fails to conduct himself/herself in accordance with generally  accepted standards of morality, (ii) engages in any activity which reflects adversely on the image, reputation or goodwill of the Sponsor or (iii)  disparages the products or services of the Sponsor; provided, however, the Sponsor shall not have the right to terminate this Agreement if Racing,  within fifteen (15) days after receipt of written notice by the Sponsor terminates the employment of, or otherwise dismisses from the racing team,  the driver(s), general manager(s) or other member(s) of Racing engaging in the offensive conduct. Upon termination, the Sponsor shall be entitled  to a pro rata refund of monies paid for services not yet performed by Racing based upon the number of races for the applicable racing season. The  Sponsor\\'s decision with respect to all matters arising under this Section shall be conclusive.      4\\n\\n\\n\\n\\n\\n10. Remedies. If either party breaches any provision of this Agreement, the other party shall be entitled to seek monetary damages and, if  appropriate, equitable relief to require the performance of the obligations hereunder.\\n\\n11. Assignment. Neither party shall assign any of its rights or obligations hereunder without the prior written consent of the other party.\\n\\n12. Entire Agreement; Amendment and Waiver; Confidentiality. This Agreement constitutes the entire agreement between Racing and the  Sponsor with respect to the subject matter hereof and supercedes all prior agreements and understandings. Any amendment of this Agreement  must be by a written instrument signed by both parties, and any waiver of any provision hereof must be in writing, signed by the party agreeing to  such waiver. Each of the parties hereto agrees to hold in confidence the terms hereof and, unless otherwise required by law, neither party shall  release, disclose or publish any of the terms hereof without the prior written consent of the other party.\\n\\n13. Notices. All notices and communications to be made with respect to this Agreement shall be in writing and shall be effective only when  delivered by (i) hand, (ii) prepaid certified United States mail, return receipt requested, or (iii) overnight delivery service providing proof of delivery,  addressed as follows:\\n\\nIf to Racing:   Stallings Capital Group Consultants, Ltd., dba Bob Stallings Racing   Attention: Robert W. Stallings, President   4 Windsor Ridge   Frisco, Texas 75034\\n\\nif to the Sponsor:   GAINSCO, Inc.   Attention: Glenn W. Anderson, President   3333 Lee Parkway, Suite 1200   Dallas, Texas 75219\\n\\nEither party may change the name or address for notice by providing a written notice of such change in accordance with this Section of the  Agreement.\\n\\n14. Termination by the Sponsor. Notwithstanding the provisions of Section 1 hereof, the Sponsor shall have the right at any time prior to  December 31, 2010 to terminate this Agreement by giving written notice of such termination to Racing. In the event of such a termination, (i) the  Sponsor shall have no further obligation to make payments toward the sponsorship fee contemplated in Section 3 hereof, (ii) Racing shall have no  further obligation to provide any Benefits hereunder, and (iii) the remaining provisions of this Agreement shall remain in full force and effect.\\n\\n15. Miscellaneous. (a) This Agreement may be executed in two counterparts, each of which shall be deemed to be an original, but both of  which shall constitute a single agreement.      5\\n\\n\\n\\n\\n\\n(b) The headings and sections of this Agreement are for convenience only and shall not affect the interpretation of any provision hereof.\\n\\n(c) This Agreement shall be governed and construed in accordance with the internal laws of the State of Texas, without giving effect to  principles of conflict of laws.\\n\\nThis Agreement is executed as of the date first above written.\\n\\n   6\\n\\nSTALLINGS CAPITAL GROUP CONSULTANTS, LTD., DBA BOB  STALLINGS RACING     GAINSCO, INC.\\n\\nBy:  /s/ Robert W. Stallings     By:  /s/ Glenn W. Anderson    Robert W. Stallings, President       Glenn W. Anderson, President',\n",
    "  'question': 'Highlight the parts (if any) of this contract related to \"Effective Date\" that should be reviewed by a lawyer. Details: The date when the contract is effective\\xa0'},\n",
    "    {'taskname': 'cuad',\n",
    "  'context': 'Exhibit 10.41\\n\\nSPONSORSHIP AGREEMENT\\n\\nThis Sponsorship Agreement (the \"Agreement\") is entered into effective January 1, 2010 by and between Stallings Capital Group  Consultants, Ltd., a Texas limited partnership dba Bob Stallings Racing (\"Racing\"), and GAINSCO, INC., a Texas corporation (the \"Sponsor\").\\n\\nRacing organized and operated a racing team engaging in Daytona Prototype Series auto racing (the \"Racing Team\") in professional races in  2005 through 2008, and the Sponsor was the primary sponsor of the Racing Team pursuant to Sponsorship Agreements dated February 7, 2005,  February 1, 2006, January 1, 2007, January 1, 2008 and January 1, 2009. Racing has invited the Sponsor to continue to act as the primary sponsor of  the Racing Team for 2010, and the Sponsor desires to act in that capacity. In consideration of the sponsorship fee provided for herein, the parties  desire to enter into this Agreement to govern the terms of such sponsorship in 2010.\\n\\nNow, therefore, Racing and the Sponsor hereby agree as follows:\\n\\n1. Term. Subject to the provisions of Section 14 hereof, the term of this Agreement and the sponsorship described herein shall commence on  January 1, 2010 and extend through December 31, 2010.\\n\\n2. Advertising and Other Benefits. Subject to payment by the Sponsor of the sponsorship fee provided for herein, during the term of this  Agreement Racing shall cause the Racing Team to provide for the Sponsor\\'s benefit all of the benefits customarily associated with the  sponsorship of a Daytona Prototype Series racing team and consistent with the benefits provided to the Sponsor in 2005 - 2009 (individually, a  \"Benefit,\" and collectively, the \"Benefits\"), including but not limited to the following:   (i) displaying prominent identification of the Sponsor\\'s name and/or logo in signage on the race car and racing suits and, where  appropriate, on other team equipment (subject to approval by the Sponsor);   (ii) making available for the use of the Sponsor (x) the personalities associated with the Racing Team, including without limitation  the name, voice, picture, portrait, likeness, persona and/or signature of each driver for endorsements, commercial advertising and  promotions in any and all media throughout the world during the term of this Agreement, (y) the Racing Team\\'s home base facilities in  Texas, and (z) those facilities designated or assigned for the use of the Racing Team at each race and race location at which the Racing  Team actually participates in the race, all for appropriate public relations and other promotional and marketing purposes. Racing agrees  that it will actively participate in the Rolex 24 at Daytona in January, 2010. As it concerns (y) and (z) above, access shall be subject to  appropriate security and safety restrictions designated by the applicable racing location and the Racing Team;\\n\\n\\n\\n\\n\\n(iii) making available for the use of the Sponsor a non-racing look-alike (a \"Show Car\") of the GAINSCO 99 race car (the \"Car\")  used by the Racing Team. Subject to the Sponsor\\'s first right to use the Show Car, it will also be made available to Racing when such  use does not interfere with the Sponsor\\'s use of the Show Car;   (iv) allowing the Sponsor the use of the likeness of the Car, including all paint and graphics, for promotion and advertising of or  by the Sponsor, and Racing shall be responsible for all necessary consents and permissions from any other sponsors to be sure the  Sponsor can use the likeness of the Car as specified herein;   (v) prohibiting the endorsement by Racing and any members of Racing, including the drivers, of any entities, products or  services which are in direct competition or otherwise inconsistent with the Sponsor or it products or services, unless such  endorsement activity is approved in writing by Racing and the Sponsor; and   (vi) allowing the Sponsor to use the conference room and other areas of the racing shop and garage for meetings and similar  events, provided that the Sponsor gives prior notice of the need for such use, and such use does not interfere with operations of the  racing shop and garage and is otherwise consistent with reasonable requirements imposed by Racing to assure orderly operations and  provide for adequate safety measures at all times.\\n\\n3. Sponsorship Fee. The Sponsor shall pay to Racing a sponsorship fee in the amount of $750,000.00 for the term of this Agreement, payable  in an initial installment payable on or before February 1, 2010 in the amount of $350,000.00 and ten installments of $40,000.00 on or before the first  day of each month commencing March 1, 2010 and ending with the installment due on December 1, 2010 (unless this Agreement is sooner  terminated pursuant to Section 14 hereof, in which case Sponsor shall have no obligation to make any payments after the date of termination).\\n\\n4. Compliance with Applicable Rules and Regulations. Provision of the Benefits pursuant to this Agreement is subject to rules and  requirements of each organization and venue hosting a racing event in which the Racing Team competes during the term hereof, and the Sponsor  agrees to submit to Racing all advertising and other promotional material relating to each such event in sufficient time to enable Racing to assure  compliance with such rules and requirements. If as a result of such rules and requirements Racing is unable to provide a Benefit in the form  requested by the Sponsor, Racing shall be permitted to provide a substitute promotion or advertisement in compliance with such requirements.      2\\n\\n\\n\\n\\n\\n5. Sponsor\\'s Maximum Obligation; Indemnification. Racing represents to the Sponsor that the Sponsor\\'s aggregate obligation hereunder  will not exceed the amount of the sponsorship fee set forth in Section 3 hereof (or such lesser amount as is payable by the Sponsor in the event  that this Agreement is terminated pursuant to Section 14 hereof), plus, if applicable, collection costs that may be reasonably incurred by Racing in  a legal proceeding to collect all or any part thereof (the \"Maximum Obligation\"). Racing agrees to indemnify the Sponsor and its officers, directors,  agents and employees and to hold them harmless from any loss, claim, cost, damage or liability in excess of the Maximum Obligation which (i) the  Sponsor shall incur as a result of this Agreement, or (ii) arises from any failure by Racing to perform any of its obligations hereunder.\\n\\n6. Retention of Rights. The only rights granted to the Sponsor hereunder are the right to receive the Benefits, and Racing hereby retains all  other rights with respect to the Racing Team, including but not limited to logos, symbols, names and other marks and intellectual property of the  Racing Team, and any proceeds derived by the Racing Team. The Sponsor hereby retains and does not grant any rights to Racing to use any of its  logos, symbols, names or other marks or intellectual property, except for use as described in Section 2 hereof. In the event that this Agreement is  terminated or if the sponsorship terminates at the end of the term provided for herein, each of the parties shall retain the rights to use its logos,  symbols, names or other marks or intellectual property including, in the case of the Sponsor, the right to use the names and marks \"GAINSCO 99\",  \"the GAINSCO 99 Car\", or similar phrases or derivations thereof.\\n\\n7. Relationship to Other Sponsors. The Sponsor acknowledges that Racing has arranged and may arrange in the future for other sponsors  for the Racing Team. Racing agrees that, during the term of this Agreement, (i) Sponsor shall have the right to approve or disapprove any  additional sponsor identified by Racing, and (ii) unless another proposed sponsor has agreed to pay a sponsorship fee that exceeds the amount  paid by Sponsor, no other sponsor shall receive any benefit of greater value (including either an equivalent or a more prominent use of another  sponsor\\'s name, logo or other identifying information) than the Benefits provided to the Sponsor hereunder.\\n\\n8. Insurance.   (a) Racing shall obtain and maintain, at Racing\\'s expense, comprehensive automobile liability insurance covering all owned, non-owned and  hired vehicles used by Racing in the Business with limits of not less than $5,000,000 per occurrence combined single limit for personal injury and  property damage, including all statutory coverage for all states of operation. Racing shall also provide comprehensive (fire and theft) and collision  insurance on each vehicle used in the Business. Racing shall provide the Sponsor a certificate of insurance evidencing \"Gainsco Inc. and all  related entities\" as additional insureds, stating that such insurance is primary in coverage to any other insurance which may be available the  Sponsor, and providing at least thirty (30) days\\' prior written notice to the Sponsor of cancellation, modification or material change to the policy.\\n\\n(b) Racing shall obtain and maintain pursuant to the terms of this Agreement, at its sole expense, the following types of insurance coverage,  with minimum limits as set forth below:\\n\\n(i) Commercial General Liability covering liability arising from premises, operations, independent contractors, personal and advertising injury  and contractual liability—$5,000,000 each occurrence.      3\\n\\n\\n\\n\\n\\n(ii) Racing Owners\\' Sponsors (Spectators) Legal Liability including Participant Legal Liability—$5,000,000 each occurrence.\\n\\n(iii) Business Automobile Liability covering all owned, hired and non-owned vehicles—$5,000,000 each occurrence, including statutory  coverages for all states of operations.\\n\\n(iv) Workers Compensation—statutory limits for all states of operation.\\n\\n(v) Employers Liability—$5,000,000 each employee for bodily injury by accident and $500,000 each employee for bodily injury by disease.\\n\\nAll policies of insurance procured by Racing herein shall be written as primary policies, not contributing with or in excess of coverage that the  Sponsor may carry. If Racing\\'s liability policies do not contain the standard separation of insureds provision, or a substantially similar clause, they  shall be endorsed to provide cross-liability coverage.\\n\\n(c) Racing shall provide the Sponsor with a certificate of insurance evidence compliance with the insurance requirements set forth above.  Certificates shall provide that \"Gainsco Inc. and all related entities\" shall be named as additional insureds on all liability policies, stating that such  insurance is primary in coverage to any other insurance which may be available to the Sponsor, and providing at least thirty (30) days\\' prior  written notice to the Sponsor of termination, cancellation, modification or material change to the policy.\\n\\n(d) Such certificates shall be in a form acceptable to, and underwritten by insurance company(ies) reasonably satisfactory to the Sponsor. By  requiring insurance herein, the Sponsor does not represent that coverage limits will necessarily be adequate to protect Racing. The purchase of  appropriate insurance coverage by Racing or the furnishing of certificates of insurance shall not release Racing from its obligations and liabilities  under this Agreement.\\n\\n9. Conduct. Racing and all Racing members, including but not limited to all drivers, agree to use best efforts to conduct themselves in such a  manner so as not to reflect unfavorably upon the Sponsor or its products. The Sponsor shall have the right to terminate this Agreement on written  notice to Racing if any driver, the general manager or any other member of Racing (i) fails to conduct himself/herself in accordance with generally  accepted standards of morality, (ii) engages in any activity which reflects adversely on the image, reputation or goodwill of the Sponsor or (iii)  disparages the products or services of the Sponsor; provided, however, the Sponsor shall not have the right to terminate this Agreement if Racing,  within fifteen (15) days after receipt of written notice by the Sponsor terminates the employment of, or otherwise dismisses from the racing team,  the driver(s), general manager(s) or other member(s) of Racing engaging in the offensive conduct. Upon termination, the Sponsor shall be entitled  to a pro rata refund of monies paid for services not yet performed by Racing based upon the number of races for the applicable racing season. The  Sponsor\\'s decision with respect to all matters arising under this Section shall be conclusive.      4\\n\\n\\n\\n\\n\\n10. Remedies. If either party breaches any provision of this Agreement, the other party shall be entitled to seek monetary damages and, if  appropriate, equitable relief to require the performance of the obligations hereunder.\\n\\n11. Assignment. Neither party shall assign any of its rights or obligations hereunder without the prior written consent of the other party.\\n\\n12. Entire Agreement; Amendment and Waiver; Confidentiality. This Agreement constitutes the entire agreement between Racing and the  Sponsor with respect to the subject matter hereof and supercedes all prior agreements and understandings. Any amendment of this Agreement  must be by a written instrument signed by both parties, and any waiver of any provision hereof must be in writing, signed by the party agreeing to  such waiver. Each of the parties hereto agrees to hold in confidence the terms hereof and, unless otherwise required by law, neither party shall  release, disclose or publish any of the terms hereof without the prior written consent of the other party.\\n\\n13. Notices. All notices and communications to be made with respect to this Agreement shall be in writing and shall be effective only when  delivered by (i) hand, (ii) prepaid certified United States mail, return receipt requested, or (iii) overnight delivery service providing proof of delivery,  addressed as follows:\\n\\nIf to Racing:   Stallings Capital Group Consultants, Ltd., dba Bob Stallings Racing   Attention: Robert W. Stallings, President   4 Windsor Ridge   Frisco, Texas 75034\\n\\nif to the Sponsor:   GAINSCO, Inc.   Attention: Glenn W. Anderson, President   3333 Lee Parkway, Suite 1200   Dallas, Texas 75219\\n\\nEither party may change the name or address for notice by providing a written notice of such change in accordance with this Section of the  Agreement.\\n\\n14. Termination by the Sponsor. Notwithstanding the provisions of Section 1 hereof, the Sponsor shall have the right at any time prior to  December 31, 2010 to terminate this Agreement by giving written notice of such termination to Racing. In the event of such a termination, (i) the  Sponsor shall have no further obligation to make payments toward the sponsorship fee contemplated in Section 3 hereof, (ii) Racing shall have no  further obligation to provide any Benefits hereunder, and (iii) the remaining provisions of this Agreement shall remain in full force and effect.\\n\\n15. Miscellaneous. (a) This Agreement may be executed in two counterparts, each of which shall be deemed to be an original, but both of  which shall constitute a single agreement.      5\\n\\n\\n\\n\\n\\n(b) The headings and sections of this Agreement are for convenience only and shall not affect the interpretation of any provision hereof.\\n\\n(c) This Agreement shall be governed and construed in accordance with the internal laws of the State of Texas, without giving effect to  principles of conflict of laws.\\n\\nThis Agreement is executed as of the date first above written.\\n\\n   6\\n\\nSTALLINGS CAPITAL GROUP CONSULTANTS, LTD., DBA BOB  STALLINGS RACING     GAINSCO, INC.\\n\\nBy:  /s/ Robert W. Stallings     By:  /s/ Glenn W. Anderson    Robert W. Stallings, President       Glenn W. Anderson, President',\n",
    "  'question': 'Highlight the parts (if any) of this contract related to \"Expiration Date\" that should be reviewed by a lawyer. Details: On what date will the contract\\'s initial term expire?'},\n",
    "    {'taskname': 'cuad',\n",
    "  'context': 'Exhibit 10.41\\n\\nSPONSORSHIP AGREEMENT\\n\\nThis Sponsorship Agreement (the \"Agreement\") is entered into effective January 1, 2010 by and between Stallings Capital Group  Consultants, Ltd., a Texas limited partnership dba Bob Stallings Racing (\"Racing\"), and GAINSCO, INC., a Texas corporation (the \"Sponsor\").\\n\\nRacing organized and operated a racing team engaging in Daytona Prototype Series auto racing (the \"Racing Team\") in professional races in  2005 through 2008, and the Sponsor was the primary sponsor of the Racing Team pursuant to Sponsorship Agreements dated February 7, 2005,  February 1, 2006, January 1, 2007, January 1, 2008 and January 1, 2009. Racing has invited the Sponsor to continue to act as the primary sponsor of  the Racing Team for 2010, and the Sponsor desires to act in that capacity. In consideration of the sponsorship fee provided for herein, the parties  desire to enter into this Agreement to govern the terms of such sponsorship in 2010.\\n\\nNow, therefore, Racing and the Sponsor hereby agree as follows:\\n\\n1. Term. Subject to the provisions of Section 14 hereof, the term of this Agreement and the sponsorship described herein shall commence on  January 1, 2010 and extend through December 31, 2010.\\n\\n2. Advertising and Other Benefits. Subject to payment by the Sponsor of the sponsorship fee provided for herein, during the term of this  Agreement Racing shall cause the Racing Team to provide for the Sponsor\\'s benefit all of the benefits customarily associated with the  sponsorship of a Daytona Prototype Series racing team and consistent with the benefits provided to the Sponsor in 2005 - 2009 (individually, a  \"Benefit,\" and collectively, the \"Benefits\"), including but not limited to the following:   (i) displaying prominent identification of the Sponsor\\'s name and/or logo in signage on the race car and racing suits and, where  appropriate, on other team equipment (subject to approval by the Sponsor);   (ii) making available for the use of the Sponsor (x) the personalities associated with the Racing Team, including without limitation  the name, voice, picture, portrait, likeness, persona and/or signature of each driver for endorsements, commercial advertising and  promotions in any and all media throughout the world during the term of this Agreement, (y) the Racing Team\\'s home base facilities in  Texas, and (z) those facilities designated or assigned for the use of the Racing Team at each race and race location at which the Racing  Team actually participates in the race, all for appropriate public relations and other promotional and marketing purposes. Racing agrees  that it will actively participate in the Rolex 24 at Daytona in January, 2010. As it concerns (y) and (z) above, access shall be subject to  appropriate security and safety restrictions designated by the applicable racing location and the Racing Team;\\n\\n\\n\\n\\n\\n(iii) making available for the use of the Sponsor a non-racing look-alike (a \"Show Car\") of the GAINSCO 99 race car (the \"Car\")  used by the Racing Team. Subject to the Sponsor\\'s first right to use the Show Car, it will also be made available to Racing when such  use does not interfere with the Sponsor\\'s use of the Show Car;   (iv) allowing the Sponsor the use of the likeness of the Car, including all paint and graphics, for promotion and advertising of or  by the Sponsor, and Racing shall be responsible for all necessary consents and permissions from any other sponsors to be sure the  Sponsor can use the likeness of the Car as specified herein;   (v) prohibiting the endorsement by Racing and any members of Racing, including the drivers, of any entities, products or  services which are in direct competition or otherwise inconsistent with the Sponsor or it products or services, unless such  endorsement activity is approved in writing by Racing and the Sponsor; and   (vi) allowing the Sponsor to use the conference room and other areas of the racing shop and garage for meetings and similar  events, provided that the Sponsor gives prior notice of the need for such use, and such use does not interfere with operations of the  racing shop and garage and is otherwise consistent with reasonable requirements imposed by Racing to assure orderly operations and  provide for adequate safety measures at all times.\\n\\n3. Sponsorship Fee. The Sponsor shall pay to Racing a sponsorship fee in the amount of $750,000.00 for the term of this Agreement, payable  in an initial installment payable on or before February 1, 2010 in the amount of $350,000.00 and ten installments of $40,000.00 on or before the first  day of each month commencing March 1, 2010 and ending with the installment due on December 1, 2010 (unless this Agreement is sooner  terminated pursuant to Section 14 hereof, in which case Sponsor shall have no obligation to make any payments after the date of termination).\\n\\n4. Compliance with Applicable Rules and Regulations. Provision of the Benefits pursuant to this Agreement is subject to rules and  requirements of each organization and venue hosting a racing event in which the Racing Team competes during the term hereof, and the Sponsor  agrees to submit to Racing all advertising and other promotional material relating to each such event in sufficient time to enable Racing to assure  compliance with such rules and requirements. If as a result of such rules and requirements Racing is unable to provide a Benefit in the form  requested by the Sponsor, Racing shall be permitted to provide a substitute promotion or advertisement in compliance with such requirements.      2\\n\\n\\n\\n\\n\\n5. Sponsor\\'s Maximum Obligation; Indemnification. Racing represents to the Sponsor that the Sponsor\\'s aggregate obligation hereunder  will not exceed the amount of the sponsorship fee set forth in Section 3 hereof (or such lesser amount as is payable by the Sponsor in the event  that this Agreement is terminated pursuant to Section 14 hereof), plus, if applicable, collection costs that may be reasonably incurred by Racing in  a legal proceeding to collect all or any part thereof (the \"Maximum Obligation\"). Racing agrees to indemnify the Sponsor and its officers, directors,  agents and employees and to hold them harmless from any loss, claim, cost, damage or liability in excess of the Maximum Obligation which (i) the  Sponsor shall incur as a result of this Agreement, or (ii) arises from any failure by Racing to perform any of its obligations hereunder.\\n\\n6. Retention of Rights. The only rights granted to the Sponsor hereunder are the right to receive the Benefits, and Racing hereby retains all  other rights with respect to the Racing Team, including but not limited to logos, symbols, names and other marks and intellectual property of the  Racing Team, and any proceeds derived by the Racing Team. The Sponsor hereby retains and does not grant any rights to Racing to use any of its  logos, symbols, names or other marks or intellectual property, except for use as described in Section 2 hereof. In the event that this Agreement is  terminated or if the sponsorship terminates at the end of the term provided for herein, each of the parties shall retain the rights to use its logos,  symbols, names or other marks or intellectual property including, in the case of the Sponsor, the right to use the names and marks \"GAINSCO 99\",  \"the GAINSCO 99 Car\", or similar phrases or derivations thereof.\\n\\n7. Relationship to Other Sponsors. The Sponsor acknowledges that Racing has arranged and may arrange in the future for other sponsors  for the Racing Team. Racing agrees that, during the term of this Agreement, (i) Sponsor shall have the right to approve or disapprove any  additional sponsor identified by Racing, and (ii) unless another proposed sponsor has agreed to pay a sponsorship fee that exceeds the amount  paid by Sponsor, no other sponsor shall receive any benefit of greater value (including either an equivalent or a more prominent use of another  sponsor\\'s name, logo or other identifying information) than the Benefits provided to the Sponsor hereunder.\\n\\n8. Insurance.   (a) Racing shall obtain and maintain, at Racing\\'s expense, comprehensive automobile liability insurance covering all owned, non-owned and  hired vehicles used by Racing in the Business with limits of not less than $5,000,000 per occurrence combined single limit for personal injury and  property damage, including all statutory coverage for all states of operation. Racing shall also provide comprehensive (fire and theft) and collision  insurance on each vehicle used in the Business. Racing shall provide the Sponsor a certificate of insurance evidencing \"Gainsco Inc. and all  related entities\" as additional insureds, stating that such insurance is primary in coverage to any other insurance which may be available the  Sponsor, and providing at least thirty (30) days\\' prior written notice to the Sponsor of cancellation, modification or material change to the policy.\\n\\n(b) Racing shall obtain and maintain pursuant to the terms of this Agreement, at its sole expense, the following types of insurance coverage,  with minimum limits as set forth below:\\n\\n(i) Commercial General Liability covering liability arising from premises, operations, independent contractors, personal and advertising injury  and contractual liability—$5,000,000 each occurrence.      3\\n\\n\\n\\n\\n\\n(ii) Racing Owners\\' Sponsors (Spectators) Legal Liability including Participant Legal Liability—$5,000,000 each occurrence.\\n\\n(iii) Business Automobile Liability covering all owned, hired and non-owned vehicles—$5,000,000 each occurrence, including statutory  coverages for all states of operations.\\n\\n(iv) Workers Compensation—statutory limits for all states of operation.\\n\\n(v) Employers Liability—$5,000,000 each employee for bodily injury by accident and $500,000 each employee for bodily injury by disease.\\n\\nAll policies of insurance procured by Racing herein shall be written as primary policies, not contributing with or in excess of coverage that the  Sponsor may carry. If Racing\\'s liability policies do not contain the standard separation of insureds provision, or a substantially similar clause, they  shall be endorsed to provide cross-liability coverage.\\n\\n(c) Racing shall provide the Sponsor with a certificate of insurance evidence compliance with the insurance requirements set forth above.  Certificates shall provide that \"Gainsco Inc. and all related entities\" shall be named as additional insureds on all liability policies, stating that such  insurance is primary in coverage to any other insurance which may be available to the Sponsor, and providing at least thirty (30) days\\' prior  written notice to the Sponsor of termination, cancellation, modification or material change to the policy.\\n\\n(d) Such certificates shall be in a form acceptable to, and underwritten by insurance company(ies) reasonably satisfactory to the Sponsor. By  requiring insurance herein, the Sponsor does not represent that coverage limits will necessarily be adequate to protect Racing. The purchase of  appropriate insurance coverage by Racing or the furnishing of certificates of insurance shall not release Racing from its obligations and liabilities  under this Agreement.\\n\\n9. Conduct. Racing and all Racing members, including but not limited to all drivers, agree to use best efforts to conduct themselves in such a  manner so as not to reflect unfavorably upon the Sponsor or its products. The Sponsor shall have the right to terminate this Agreement on written  notice to Racing if any driver, the general manager or any other member of Racing (i) fails to conduct himself/herself in accordance with generally  accepted standards of morality, (ii) engages in any activity which reflects adversely on the image, reputation or goodwill of the Sponsor or (iii)  disparages the products or services of the Sponsor; provided, however, the Sponsor shall not have the right to terminate this Agreement if Racing,  within fifteen (15) days after receipt of written notice by the Sponsor terminates the employment of, or otherwise dismisses from the racing team,  the driver(s), general manager(s) or other member(s) of Racing engaging in the offensive conduct. Upon termination, the Sponsor shall be entitled  to a pro rata refund of monies paid for services not yet performed by Racing based upon the number of races for the applicable racing season. The  Sponsor\\'s decision with respect to all matters arising under this Section shall be conclusive.      4\\n\\n\\n\\n\\n\\n10. Remedies. If either party breaches any provision of this Agreement, the other party shall be entitled to seek monetary damages and, if  appropriate, equitable relief to require the performance of the obligations hereunder.\\n\\n11. Assignment. Neither party shall assign any of its rights or obligations hereunder without the prior written consent of the other party.\\n\\n12. Entire Agreement; Amendment and Waiver; Confidentiality. This Agreement constitutes the entire agreement between Racing and the  Sponsor with respect to the subject matter hereof and supercedes all prior agreements and understandings. Any amendment of this Agreement  must be by a written instrument signed by both parties, and any waiver of any provision hereof must be in writing, signed by the party agreeing to  such waiver. Each of the parties hereto agrees to hold in confidence the terms hereof and, unless otherwise required by law, neither party shall  release, disclose or publish any of the terms hereof without the prior written consent of the other party.\\n\\n13. Notices. All notices and communications to be made with respect to this Agreement shall be in writing and shall be effective only when  delivered by (i) hand, (ii) prepaid certified United States mail, return receipt requested, or (iii) overnight delivery service providing proof of delivery,  addressed as follows:\\n\\nIf to Racing:   Stallings Capital Group Consultants, Ltd., dba Bob Stallings Racing   Attention: Robert W. Stallings, President   4 Windsor Ridge   Frisco, Texas 75034\\n\\nif to the Sponsor:   GAINSCO, Inc.   Attention: Glenn W. Anderson, President   3333 Lee Parkway, Suite 1200   Dallas, Texas 75219\\n\\nEither party may change the name or address for notice by providing a written notice of such change in accordance with this Section of the  Agreement.\\n\\n14. Termination by the Sponsor. Notwithstanding the provisions of Section 1 hereof, the Sponsor shall have the right at any time prior to  December 31, 2010 to terminate this Agreement by giving written notice of such termination to Racing. In the event of such a termination, (i) the  Sponsor shall have no further obligation to make payments toward the sponsorship fee contemplated in Section 3 hereof, (ii) Racing shall have no  further obligation to provide any Benefits hereunder, and (iii) the remaining provisions of this Agreement shall remain in full force and effect.\\n\\n15. Miscellaneous. (a) This Agreement may be executed in two counterparts, each of which shall be deemed to be an original, but both of  which shall constitute a single agreement.      5\\n\\n\\n\\n\\n\\n(b) The headings and sections of this Agreement are for convenience only and shall not affect the interpretation of any provision hereof.\\n\\n(c) This Agreement shall be governed and construed in accordance with the internal laws of the State of Texas, without giving effect to  principles of conflict of laws.\\n\\nThis Agreement is executed as of the date first above written.\\n\\n   6\\n\\nSTALLINGS CAPITAL GROUP CONSULTANTS, LTD., DBA BOB  STALLINGS RACING     GAINSCO, INC.\\n\\nBy:  /s/ Robert W. Stallings     By:  /s/ Glenn W. Anderson    Robert W. Stallings, President       Glenn W. Anderson, President',\n",
    "  'question': 'Highlight the parts (if any) of this contract related to \"Governing Law\" that should be reviewed by a lawyer. Details: Which state/country\\'s law governs the interpretation of the contract?'}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "84d089f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 11:01:56 gpt_prompt_learning_dataset:85] Loading and tokenizing dataset ... \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72fa4310a3ed43fabb8117c148a990e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2024-03-06 11:01:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 11:01:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 11:01:56 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 11:01:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 11:01:57 gpt_prompt_learning_dataset:274] Input greater than max sequence length. Attempting to truncate: 'context' in task: 'cuad'\n",
      "[NeMo I 2024-03-06 11:01:57 gpt_prompt_learning_dataset:196] Skipped 0 sentences, sequence length too short or too long even after truncation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NeMo W 2024-03-06 11:01:57 nemo_logging:349] /usr/local/lib/python3.10/dist-packages/nemo/collections/nlp/modules/common/text_generation_utils.py:311: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at /opt/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "      string_tensor = torch.as_tensor(\n",
      "    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The prediction results:\n",
      "\n",
      "Sponsorship Agreement\n",
      "------------------------------\n",
      "January 1, 2010\n",
      "------------------------------\n",
      "This Agreement shall be effective on January 1, 2010.\n",
      "\n",
      "Question: What is the significance of the \"Effective Date\" in this contract?\n",
      "------------------------------\n",
      "This Agreement shall be in effect for the term of this Agreement and shall automatically terminate upon the  expiration of the term of this Agreement.\n",
      "\n",
      "9\n",
      "------------------------------\n",
      "This Agreement shall be governed by and construed in accordance with the laws of the State of Texas, without regard to its conflict of laws principles.\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "responses = mymodel.generate(inputs=test_examples, length_params=None)\n",
    "print('The prediction results:\\n')\n",
    "for response in responses['sentences']:\n",
    "    parts = response.split(\"Answer:\", 1)\n",
    "    if len(parts) > 1:\n",
    "        answer = parts[1].strip()\n",
    "        print(answer)\n",
    "    else:\n",
    "        print(\"No answer found\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5bb6df",
   "metadata": {},
   "source": [
    "#### Expected Output\n",
    "```python\n",
    "[NeMo I 2023-08-17 19:36:12 gpt_prompt_learning_dataset:85] Loading and tokenizing dataset ... \n",
    "  0%|          | 0/5 [00:00<?, ?it/s]\n",
    "[NeMo I 2023-08-17 19:36:12 gpt_prompt_learning_dataset:196] Skipped 0 sentences, sequence length too short or too long even after truncation\n",
    "The prediction results:\n",
    "\n",
    "SPONSORSHIP AGREEMENT\n",
    "------------------------------\n",
    "January 1, 2010\n",
    "------------------------------\n",
    "January 1, 2010\n",
    "------------------------------\n",
    "This Agreement shall commence on  January 1, 2010 and extend through December 31, 2010.\n",
    "------------------------------\n",
    "This Agreement shall be governed by and construed in accordance with the laws of the State of Texas without regard to conflicts of laws principles.\n",
    "------------------------------\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ba8aa3",
   "metadata": {},
   "source": [
    "## Multi-task Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8aa6db",
   "metadata": {},
   "source": [
    "This section will dive into multi-task inference using prompt-tuned language models. These models are versatile because they've learned from various prompts during training, enabling them to handle different tasks effectively. The process eliminates the need for separate fine-tuning per task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e746610c",
   "metadata": {},
   "source": [
    "#### Preparing for Multi-Task Inference:\n",
    "To perform multi-task inference using prompt-tuned models, you need to have the following components ready:\n",
    "\n",
    "- A prompt-tuned model saved in a .nemo file format (virtual_prompt_model_file).\n",
    "- A pretrained GPT model in .nemo file format (gpt_model_file)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685591c7",
   "metadata": {},
   "source": [
    "The inference file can contain a mix of prompts from all the tasks the model has been prompt tuned on."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c63649",
   "metadata": {},
   "source": [
    "```python\n",
    "python megatron_gpt_prompt_learning_eval.py \\\n",
    "            virtual_prompt_model_file=PATH_TO_NEMO_PROMPT_LEARNING_MODEL_FILE \\\n",
    "            gpt_model_file=PATH_TO_FROZEN_GPT_MODEL_FILE \\\n",
    "            inference.greedy=True \\\n",
    "            inference.add_BOS=False \\\n",
    "            trainer.devices=1 \\\n",
    "            trainer.num_nodes=1 \\\n",
    "            tensor_model_parallel_size=1 \\\n",
    "            pipeline_model_parallel_size=1 \\\n",
    "            pred_file_path=PATH_WHERE_PRED_TEXT_FILE_WILL_BE_SAVED \\\n",
    "            data_paths=[path/to/dataset1.jsonl, path/to/dataset2.jsonl]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ee674b",
   "metadata": {},
   "source": [
    "virtual_prompt_model_file should be a path to a .nemo file saved after p-tuning/prompt tuning, and gpt_model_file is still the path to the gpt model’s .nemo file.\n",
    "\n",
    "data_paths should be a list of .json or .jsonl files containing JSON objects similar to the ones used during prompt learning. They should have keys that match the fields specified in the prompt template. Fields can be dropped from the prompt dictionary, and their corresponding section of the prompt template will be automatically removed.\n",
    "\n",
    "Generally, prompt learning inference is like running inference with a GPT model. The only difference is you need to add \n",
    "`virtual_prompt_model_file=PATH_TO_NEMO_PROMPT_LEARNING_MODEL_FILE` to your command if you're using a p-tuned/prompt-tuned model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "caaba353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Define the path to the predictions folder and the predictions file\n",
    "predictions_folder = \"../../results/activity2/predictions\"\n",
    "predictions_file = \"cuad_predictions.txt\"\n",
    "predictions_path = os.path.join(predictions_folder, predictions_file)\n",
    "\n",
    "# Check if the predictions folder exists, and create it if not\n",
    "if not os.path.exists(predictions_folder):\n",
    "    os.makedirs(predictions_folder)\n",
    "\n",
    "# Check if the predictions file already exists\n",
    "if not os.path.exists(predictions_path):\n",
    "    # If it doesn't exist, create an empty file\n",
    "    with open(predictions_path, 'w') as f:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58af3580",
   "metadata": {},
   "source": [
    "When running the cell below, you can experience the error:`errno: 98 - Address already in use`\n",
    "\n",
    "\n",
    "```python\n",
    "...\n",
    "[NeMo I 2023-11-03 18:35:44 save_restore_connector:249] Model MegatronGPTPromptLearningModel was successfully restored from /workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-11-03_14-50-49/checkpoints/p_tuning.nemo.\n",
    "Initializing distributed: GLOBAL_RANK: 0, MEMBER: 1/1\n",
    "[W socket.cpp:426] [c10d] The server socket has failed to bind to [::]:53394 (errno: 98 - Address already in use).\n",
    "[W socket.cpp:426] [c10d] The server socket has failed to bind to ?UNKNOWN? (errno: 98 - Address already in use).\n",
    "[E socket.cpp:462] [c10d] The server socket has failed to listen on any local network address.\n",
    "Error executing job with overrides: ['virtual_prompt_model_file=/workspace/jupyter_notebook/nemo/nemo_experiments/p_tuning/2023-11-03_14-50-49/checkpoints/p_tuning.nemo', 'gpt_model_file=/workspace/source_code/nemo_gpt1.3B_fp16.nemo', 'inference.greedy=True', 'inference.add_BOS=False', 'trainer.devices=1', 'trainer.num_nodes=1', 'tensor_model_parallel_size=1', 'pipeline_model_parallel_size=1', 'pred_file_path=/workspace/results/challenge_ptuning/predictions/cuad_predictions.txt', 'data_paths=[/workspace/data/cuad/cuad_short_test.jsonl]']\n",
    "Traceback (most recent call last):\n",
    "  File \"/workspace/source_code/challenge_ptuning/megatron_gpt_prompt_learning_eval.py\", line 121, in main\n",
    "    model.trainer.strategy.setup_environment()\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/ddp.py\", line 152, in setup_environment\n",
    "    self.setup_distributed()\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/nemo/collections/nlp/parts/nlp_overrides.py\", line 100, in setup_distributed\n",
    "    super().setup_distributed()\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/pytorch_lightning/strategies/ddp.py\", line 203, in setup_distributed\n",
    "    _init_dist_connection(self.cluster_environment, self._process_group_backend, timeout=self._timeout)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/lightning_fabric/utilities/distributed.py\", line 245, in _init_dist_connection\n",
    "    torch.distributed.init_process_group(torch_distributed_backend, rank=global_rank, world_size=world_size, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py\", line 145, in wrapper\n",
    "    return func(*args, **kwargs)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/distributed_c10d.py\", line 1025, in init_process_group\n",
    "    store, rank, world_size = next(rendezvous_iterator)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/rendezvous.py\", line 245, in _env_rendezvous_handler\n",
    "    store = _create_c10d_store(master_addr, master_port, rank, world_size, timeout)\n",
    "  File \"/usr/local/lib/python3.10/dist-packages/torch/distributed/rendezvous.py\", line 176, in _create_c10d_store\n",
    "    return TCPStore(\n",
    "RuntimeError: The server socket has failed to listen on any local network address. The server socket has failed to bind to [::]:53394 (errno: 98 - Address already in use). The server socket has failed to bind to ?UNKNOWN? (errno: 98 - Address already in use).\n",
    "Set the environment variable HYDRA_FULL_ERROR=1 for a complete stack trace.\n",
    "\n",
    "```\n",
    "\n",
    "The solution is to shut down the kernel of all opened notebooks and close them, including the Jupyter notebook terminal (if opened), to avoid the error below. When you restart this notebook's kernel, you do not need to run the notebook from the start; please continue running from the same cell.\n",
    "\n",
    "Run greedy inference from a p-tuned/prompt-tuned model's nemo file by setting the path for `virtual_prompt_model_file` and `gpt_model_file.`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc3ae26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "!python ../../source_code/activity2/megatron_gpt_prompt_learning_eval.py \\\n",
    "            virtual_prompt_model_file=\"/net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/jupyter_notebook/nemo/nemo_experiments/p_tuning/2024-03-06_10-41-17/checkpoints/p_tuning.nemo\" \\\n",
    "            gpt_model_file=\"/net/tscratch/people/tutorial057/nvidia-bootcamp/workspace2403/source_code/nemo_gpt1.3B_fp16.nemo\" \\\n",
    "            inference.greedy=True \\\n",
    "            inference.add_BOS=False \\\n",
    "            trainer.devices=1 \\\n",
    "            trainer.num_nodes=1 \\\n",
    "            tensor_model_parallel_size=1 \\\n",
    "            pipeline_model_parallel_size=1 \\\n",
    "            pred_file_path=\"../../results/activity2/predictions/cuad_predictions.txt\"\\\n",
    "            data_paths=[\"../../data/cuad/cuad_short_test.jsonl\"]\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507b6e93",
   "metadata": {},
   "source": [
    "##### Expected Output\n",
    "```python\n",
    "\n",
    "...\n",
    "Predicting DataLoader 0:   0%|                         | 0/2091 [00:00<?, ?it/s][NeMo W 2023-08-17 19:44:56 nemo_logging:349] /usr/local/lib/python3.8/dist-packages/apex/transformer/pipeline_parallel/utils.py:81: UserWarning: This function is only for unittest\n",
    "      warnings.warn(\"This function is only for unittest\")\n",
    "    \n",
    "Predicting DataLoader 0: 100%|██████████████| 2091/2091 [25:39<00:00,  1.36it/s]\n",
    "***************************\n",
    "Inference Complete, prediction file saved at /workspace/results/multitask_ptuning/predictions/cuad_predictions.txt\n",
    "***************************\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b70be5",
   "metadata": {},
   "source": [
    "#### Comparing Predicted Responses with Actual Answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0995fa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the text file with predicted answers\n",
    "predicted_answers = []\n",
    "with open(\"../../results/activity2/predictions/cuad_predictions.txt\", \"r\") as txt_file:\n",
    "    predicted_answers = [line.strip() for line in txt_file]\n",
    "\n",
    "# load the predicted answers\n",
    "for i in range(len(predicted_answers)):   \n",
    "    predicted_answer = predicted_answers[i]\n",
    "\n",
    "    # Extract the \"Answer:\" portion from the predicted answer line\n",
    "    predicted_answer_text = predicted_answer.split(\"Answer:\", 1)[-1].strip()\n",
    "\n",
    "    print(f\"Question {i+1} \")\n",
    "    print(f\"Predicted Answer: {predicted_answer_text}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c07ef9b",
   "metadata": {},
   "source": [
    "#### Check Your Output Against the Grundtruth \n",
    "\n",
    "**Context 1:** In 2010 the Amazon rainforest experienced another severe drought, in some ways more extreme than the 2005 drought. The affected region was approximately 1,160,000 square miles (3,000,000 km2) of rainforest, compared to 734,000 square miles (1,900,000 km2) in 2005. The 2010 drought had three epicenters where vegetation died off, whereas in 2005 the drought was focused on the southwestern part. The findings were published in the journal Science. In a typical year the Amazon absorbs 1.5 gigatons of carbon dioxide; during 2005 instead 5 gigatons were released and in 2010 8 gigatons were released.\n",
    "\n",
    "**Context 2:** The sun is a massive ball of hot, glowing gases at the center of our solar system. It provides light, heat, and energy that sustains life on Earth. The sun's surface temperature is around 5,500 degrees Celsius (9,932 degrees Fahrenheit), while its core temperature reaches about 15 million degrees Celsius (27 million degrees Fahrenheit). The sun's energy is generated through a process called nuclear fusion, where hydrogen atoms combine to form helium, releasing immense amounts of energy in the process.\n",
    "\n",
    "|Sn|Questions|Expected Answers|\n",
    "|-|-|-|\n",
    "|1|How many gigatons of carbon are absorbed by the Amazon in a typical year?|In a typical year the Amazon absorbs 1.5 gigatons of carbon dioxide|\n",
    "|2|In 2010 the affected region by the drought was approximately?|The affected region was approximately 1,160,000 square miles (3,000,000 km2) of rainforest|\n",
    "|3|Where were the findings regarding the droughts published in?|The findings were published in the journal Science|\n",
    "|4|What is the approximate surface temperature of the sun?|The sun's surface temperature is around 5,500 degrees Celsius (9,932 degrees Fahrenheit)|\n",
    "|5|How does the sun generate its energy?|The sun's energy is generated through a process called nuclear fusion, where hydrogen atoms combine to form helium, releasing immense amounts of energy in the process.|\n",
    "|6|What process is responsible for the sun's energy generation, where hydrogen atoms combine to form helium?|The process called nuclear fusion.|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2657e3",
   "metadata": {},
   "source": [
    "---\n",
    "After the Bootcamp session, you can check for the solution prototype [here](Solution_Activity2.ipynb). Please shut down the notebook kernel and click on the link below to proceed to the next lab.\n",
    "\n",
    "## <center><div style=\"text-align:center; color:#FF0000; border:3px solid red; height:80px;\"> <b><br/>[Language Model Inferencing with NeMo Megatron-GPT 5B](demo.ipynb)</b> </div> </center>\n",
    "---\n",
    "\n",
    "### Resources\n",
    "Below are resourceful links to guide you and assist you in learning more.\n",
    "- [NeMo Models](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/core.html)\n",
    "- [Core APIs](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/api.html)\n",
    "- [Experiment Manager](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/exp_manager.html)\n",
    "- [Exporting NeMo Models](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/core/export.html)\n",
    "- [Prompt Learning](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/nemo_megatron/prompt_learning.html)\n",
    "- [NeMo Megatron API](https://docs.nvidia.com/deeplearning/nemo/user-guide/docs/en/stable/nlp/api.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61302098",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8872b4a8",
   "metadata": {},
   "source": [
    "\n",
    "## Licensing\n",
    "Copyright © 2022 OpenACC-Standard.org. This material is released by OpenACC-Standard.org, in collaboration with NVIDIA Corporation, under the Creative Commons Attribution 4.0 International (CC BY 4.0). These materials include references to hardware and software developed by other entities; all applicable licensing and copyrights apply."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
